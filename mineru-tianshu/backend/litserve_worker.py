"""
MinerU Tianshu - LitServe Worker
å¤©æ¢ LitServe Worker

ä¼ä¸šçº§ AI æ•°æ®é¢„å¤„ç†å¹³å° - GPU Worker
æ”¯æŒæ–‡æ¡£ã€å›¾ç‰‡ã€éŸ³é¢‘ã€è§†é¢‘ç­‰å¤šæ¨¡æ€æ•°æ®å¤„ç†
ä½¿ç”¨ LitServe å®ç° GPU èµ„æºçš„è‡ªåŠ¨è´Ÿè½½å‡è¡¡
Worker ä¸»åŠ¨å¾ªç¯æ‹‰å–ä»»åŠ¡å¹¶å¤„ç†
"""

import os
import json
import sys
import time
import threading
import signal
import atexit
from pathlib import Path
from typing import Optional

# Fix litserve MCP compatibility with mcp>=1.1.0
# Completely disable LitServe's internal MCP to avoid conflicts with our standalone MCP Server
import litserve as ls

try:
    # Patch LitServe's MCP module to disable it completely
    import litserve.mcp as ls_mcp
    import sys
    from contextlib import asynccontextmanager

    # Inject MCPServer (mcp.server.lowlevel.Server) as dummy
    if not hasattr(ls_mcp, "MCPServer"):

        class DummyMCPServer:
            def __init__(self, *args, **kwargs):
                pass

        ls_mcp.MCPServer = DummyMCPServer
        if "litserve.mcp" in sys.modules:
            sys.modules["litserve.mcp"].MCPServer = DummyMCPServer

    # Inject StreamableHTTPSessionManager as dummy
    if not hasattr(ls_mcp, "StreamableHTTPSessionManager"):

        class DummyStreamableHTTPSessionManager:
            def __init__(self, *args, **kwargs):
                pass

        ls_mcp.StreamableHTTPSessionManager = DummyStreamableHTTPSessionManager
        if "litserve.mcp" in sys.modules:
            sys.modules["litserve.mcp"].StreamableHTTPSessionManager = DummyStreamableHTTPSessionManager

    # Replace _LitMCPServerConnector with a complete dummy implementation
    class DummyMCPConnector:
        """å®Œå…¨ç¦ç”¨ LitServe å†…ç½® MCP çš„ Dummy å®ç°"""

        def __init__(self, *args, **kwargs):
            self.mcp_server = None
            self.session_manager = None
            self.request_handler = None

        @asynccontextmanager
        async def lifespan(self, app):
            """ç©ºçš„ lifespan context managerï¼Œä¸åšä»»ä½•äº‹æƒ…"""
            yield  # ä»€ä¹ˆéƒ½ä¸åšï¼Œç›´æ¥è®©æœåŠ¡å™¨å¯åŠ¨

        def connect_mcp_server(self, *args, **kwargs):
            """ç©ºçš„ connect_mcp_server æ–¹æ³•ï¼Œä¸åšä»»ä½•äº‹æƒ…"""
            pass  # ä»€ä¹ˆéƒ½ä¸åšï¼Œè·³è¿‡ MCP åˆå§‹åŒ–

    # æ›¿æ¢ _LitMCPServerConnector ç±»
    ls_mcp._LitMCPServerConnector = DummyMCPConnector

    # åŒæ—¶æ›´æ–° sys.modules ä¸­çš„å¼•ç”¨
    if "litserve.mcp" in sys.modules:
        sys.modules["litserve.mcp"]._LitMCPServerConnector = DummyMCPConnector

except Exception as e:
    # If patching fails, log warning and continue
    # The server might still work or fail with a clearer error message
    import warnings

    warnings.warn(f"Failed to patch litserve.mcp (MCP will be disabled): {e}")

from loguru import logger

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„ä»¥å¯¼å…¥ MinerU
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from task_db import TaskDB
from mineru.cli.common import do_parse
from mineru.utils.model_utils import get_vram, clean_memory

# å°è¯•å¯¼å…¥ markitdown
try:
    from markitdown import MarkItDown

    MARKITDOWN_AVAILABLE = True
except ImportError:
    MARKITDOWN_AVAILABLE = False
    logger.warning("âš ï¸  markitdown not available, Office format parsing will be disabled")

# å°è¯•å¯¼å…¥ PaddleOCR-VL
try:
    from paddleocr_vl import PaddleOCRVLEngine  # noqa: F401

    PADDLEOCR_VL_AVAILABLE = True
    logger.info("âœ… PaddleOCR-VL engine available")
except ImportError:
    PADDLEOCR_VL_AVAILABLE = False
    logger.info("â„¹ï¸  PaddleOCR-VL not available (optional)")

# å°è¯•å¯¼å…¥ SenseVoice éŸ³é¢‘å¤„ç†
import importlib.util

SENSEVOICE_AVAILABLE = importlib.util.find_spec("audio_engines") is not None
if SENSEVOICE_AVAILABLE:
    logger.info("âœ… SenseVoice audio engine available")
else:
    logger.info("â„¹ï¸  SenseVoice not available (optional)")

# å°è¯•å¯¼å…¥è§†é¢‘å¤„ç†å¼•æ“
VIDEO_ENGINE_AVAILABLE = importlib.util.find_spec("video_engines") is not None
if VIDEO_ENGINE_AVAILABLE:
    logger.info("âœ… Video processing engine available")
else:
    logger.info("â„¹ï¸  Video processing engine not available (optional)")

# å°è¯•å¯¼å…¥æ°´å°å»é™¤å¼•æ“
try:
    from remove_watermark.watermark_remover import WatermarkRemover  # noqa: F401
    from remove_watermark.pdf_watermark_handler import PDFWatermarkHandler

    WATERMARK_REMOVAL_AVAILABLE = True
    logger.info("âœ… Watermark removal engine available")
except ImportError as e:
    WATERMARK_REMOVAL_AVAILABLE = False
    logger.info(f"â„¹ï¸  Watermark removal engine not available (optional): {e}")

# å°è¯•å¯¼å…¥æ ¼å¼å¼•æ“ï¼ˆä¸“ä¸šé¢†åŸŸæ ¼å¼æ”¯æŒï¼‰
try:
    from format_engines import FormatEngineRegistry, FASTAEngine, GenBankEngine

    # æ³¨å†Œæ‰€æœ‰å¼•æ“
    FormatEngineRegistry.register(FASTAEngine())
    FormatEngineRegistry.register(GenBankEngine())

    FORMAT_ENGINES_AVAILABLE = True
    logger.info("âœ… Format engines available")
    logger.info(f"   Supported extensions: {', '.join(FormatEngineRegistry.get_supported_extensions())}")
except ImportError as e:
    FORMAT_ENGINES_AVAILABLE = False
    logger.info(f"â„¹ï¸  Format engines not available (optional): {e}")


class MinerUWorkerAPI(ls.LitAPI):
    """
    MinerU Tianshu Worker API

    ç»§æ‰¿è‡ª LitServe çš„ LitAPIï¼Œå®ç°è‡ªåŠ¨è´Ÿè½½å‡è¡¡
    Worker ä¸»åŠ¨å¾ªç¯æ‹‰å–ä»»åŠ¡å¹¶å¤„ç†ï¼Œæ— éœ€å¤–éƒ¨è°ƒåº¦
    """

    def __init__(self):
        """åˆå§‹åŒ– API (ä¸æ¥å—å‚æ•°ï¼Œå‚æ•°é€šè¿‡ç±»å±æ€§ä¼ é€’)"""
        super().__init__()
        # è¿™äº›å±æ€§ä¼šåœ¨åˆ›å»ºå®ä¾‹å‰è®¾ç½®ï¼ˆé€šè¿‡ç±»å±æ€§ï¼‰
        # åœ¨ setup() ä¸­ä¼šç”¨åˆ°

    def setup(self, device):
        """
        åˆå§‹åŒ– Worker (æ¯ä¸ª GPU ä¸Šè°ƒç”¨ä¸€æ¬¡)

        Args:
            device: è®¾å¤‡ ID (cuda:0, cuda:1, cpu ç­‰)
        """
        import socket

        # é…ç½®æ¨¡å‹ä¸‹è½½æºï¼ˆå¿…é¡»åœ¨ MinerU åˆå§‹åŒ–ä¹‹å‰ï¼‰
        # ä»ç¯å¢ƒå˜é‡ MODEL_DOWNLOAD_SOURCE è¯»å–é…ç½®
        # æ”¯æŒ: modescope, huggingface, auto (é»˜è®¤)
        model_source = os.getenv("MODEL_DOWNLOAD_SOURCE", "auto").lower()

        if model_source in ["modescope", "auto"]:
            # å°è¯•ä½¿ç”¨ ModelScopeï¼ˆä¼˜å…ˆï¼‰
            try:
                import importlib.util

                if importlib.util.find_spec("modelscope") is not None:
                    logger.info("ğŸ“¦ Model download source: ModelScope (å›½å†…æ¨è)")
                    logger.info("   Note: ModelScope automatically uses China mirror for faster downloads")
                else:
                    raise ImportError("modelscope not found")
            except ImportError:
                if model_source == "modescope":
                    logger.warning("âš ï¸  ModelScope not available, falling back to HuggingFace")
                model_source = "huggingface"

        if model_source == "huggingface":
            # é…ç½® HuggingFace é•œåƒï¼ˆä»ç¯å¢ƒå˜é‡è¯»å–ï¼Œé»˜è®¤ä½¿ç”¨å›½å†…é•œåƒï¼‰
            hf_endpoint = os.getenv("HF_ENDPOINT", "https://hf-mirror.com")
            os.environ.setdefault("HF_ENDPOINT", hf_endpoint)
            logger.info(f"ğŸ“¦ Model download source: HuggingFace (via: {hf_endpoint})")
        elif model_source == "modescope":
            # å³ä½¿ä½¿ç”¨ ModelScopeï¼Œä¹Ÿä¸º MinerU è®¾ç½® HuggingFace é•œåƒï¼ˆä½œä¸ºå¤‡ç”¨ï¼‰
            # å› ä¸º MinerU å†…éƒ¨éƒ¨åˆ†æ¨¡å‹å¯èƒ½ä»éœ€è¦ä» HuggingFace ä¸‹è½½
            hf_endpoint = os.getenv("HF_ENDPOINT", "https://hf-mirror.com")
            os.environ.setdefault("HF_ENDPOINT", hf_endpoint)
            logger.info(f"   Also configured HF_ENDPOINT={hf_endpoint} for MinerU compatibility")

        self.device = device
        # ä»ç±»å±æ€§è·å–é…ç½®ï¼ˆç”± start_litserve_workers è®¾ç½®ï¼‰
        # é»˜è®¤ä½¿ç”¨å…±äº«è¾“å‡ºç›®å½•ï¼ˆDocker ç¯å¢ƒï¼‰
        default_output = os.getenv("OUTPUT_PATH", "/app/output")
        self.output_dir = getattr(self.__class__, "_output_dir", default_output)
        self.poll_interval = getattr(self.__class__, "_poll_interval", 0.5)
        self.enable_worker_loop = getattr(self.__class__, "_enable_worker_loop", True)

        # åˆ›å»ºè¾“å‡ºç›®å½•
        Path(self.output_dir).mkdir(parents=True, exist_ok=True)

        # åˆå§‹åŒ–ä»»åŠ¡æ•°æ®åº“ï¼ˆä»ç¯å¢ƒå˜é‡è¯»å–ï¼Œå…¼å®¹ Docker å’Œæœ¬åœ°ï¼‰
        db_path_env = os.getenv("DATABASE_PATH")
        if db_path_env:
            db_path = Path(db_path_env).resolve()  # ä½¿ç”¨ resolve() è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
            logger.info(f"ğŸ“Š Using DATABASE_PATH from environment: {db_path_env} -> {db_path}")
        else:
            # é»˜è®¤è·¯å¾„ï¼ˆä¸ TaskDB å’Œ AuthDB ä¿æŒä¸€è‡´ï¼‰
            db_path = Path("/app/data/db/mineru_tianshu.db").resolve()
            logger.warning(f"âš ï¸  DATABASE_PATH not set, using default: {db_path}")

        # ç¡®ä¿æ•°æ®åº“ç›®å½•å­˜åœ¨
        db_path.parent.mkdir(parents=True, exist_ok=True)

        # ä½¿ç”¨ç»å¯¹è·¯å¾„å­—ç¬¦ä¸²ä¼ é€’ç»™ TaskDB
        db_path_str = str(db_path.absolute())
        logger.info(f"ğŸ“Š Database path (absolute): {db_path_str}")

        self.task_db = TaskDB(db_path_str)

        # éªŒè¯æ•°æ®åº“è¿æ¥å¹¶è¾“å‡ºåˆå§‹ç»Ÿè®¡
        try:
            stats = self.task_db.get_queue_stats()
            logger.info(f"ğŸ“Š Database initialized: {db_path} (exists: {db_path.exists()})")
            logger.info(f"ğŸ“Š TaskDB.db_path: {self.task_db.db_path}")
            logger.info(f"ğŸ“Š Initial queue stats: {stats}")
        except Exception as e:
            logger.error(f"âŒ Failed to initialize database or get stats: {e}")
            logger.exception(e)

        # Worker çŠ¶æ€
        self.running = True
        self.current_task_id = None

        # ç”Ÿæˆå”¯ä¸€çš„ worker_id: tianshu-{hostname}-{device}-{pid}
        hostname = socket.gethostname()
        pid = os.getpid()
        self.worker_id = f"tianshu-{hostname}-{device}-{pid}"

        # åˆå§‹åŒ–å¯é€‰çš„å¤„ç†å¼•æ“
        self.markitdown = MarkItDown() if MARKITDOWN_AVAILABLE else None
        self.paddleocr_vl_engine = None  # å»¶è¿ŸåŠ è½½
        self.sensevoice_engine = None  # å»¶è¿ŸåŠ è½½
        self.video_engine = None  # å»¶è¿ŸåŠ è½½
        self.watermark_handler = None  # å»¶è¿ŸåŠ è½½

        logger.info("=" * 60)
        logger.info(f"ğŸš€ Worker Setup: {self.worker_id}")
        logger.info("=" * 60)
        logger.info(f"ğŸ“ Device: {device}")
        logger.info(f"ğŸ“‚ Output Dir: {self.output_dir}")
        logger.info(f"ğŸ—ƒï¸  Database: {db_path}")
        logger.info(f"ğŸ”„ Worker Loop: {'Enabled' if self.enable_worker_loop else 'Disabled'}")
        if self.enable_worker_loop:
            logger.info(f"â±ï¸  Poll Interval: {self.poll_interval}s")
        logger.info("")

        # æ‰“å°å¯ç”¨çš„å¼•æ“
        logger.info("ğŸ“¦ Available Engines:")
        logger.info(f"   â€¢ MarkItDown: {'âœ…' if MARKITDOWN_AVAILABLE else 'âŒ'}")
        logger.info(f"   â€¢ PaddleOCR-VL: {'âœ…' if PADDLEOCR_VL_AVAILABLE else 'âŒ'}")
        logger.info(f"   â€¢ SenseVoice: {'âœ…' if SENSEVOICE_AVAILABLE else 'âŒ'}")
        logger.info(f"   â€¢ Video Engine: {'âœ…' if VIDEO_ENGINE_AVAILABLE else 'âŒ'}")
        logger.info(f"   â€¢ Watermark Removal: {'âœ…' if WATERMARK_REMOVAL_AVAILABLE else 'âŒ'}")
        logger.info(f"   â€¢ Format Engines: {'âœ…' if FORMAT_ENGINES_AVAILABLE else 'âŒ'}")
        logger.info("")

        # æ£€æµ‹å’Œåˆå§‹åŒ–æ°´å°å»é™¤å¼•æ“ï¼ˆä»… CUDAï¼‰
        if WATERMARK_REMOVAL_AVAILABLE and "cuda" in str(device).lower():
            try:
                logger.info("ğŸ¨ Initializing watermark removal engine...")
                # PDFWatermarkHandler åªæ¥å— device å’Œ use_lama å‚æ•°
                self.watermark_handler = PDFWatermarkHandler(device=device, use_lama=True)
                logger.info("âœ… Watermark removal engine initialized")
            except Exception as e:
                logger.error(f"âŒ Failed to initialize watermark removal engine: {e}")
                self.watermark_handler = None

        logger.info("âœ… Worker ready")
        logger.info(f"   Device: {device}")
        if "cuda" in str(device).lower():
            try:
                vram_gb = get_vram(device.split(":")[-1])
                if vram_gb is not None:
                    logger.info(f"   VRAM: {vram_gb:.0f}GB")
                else:
                    logger.info("   VRAM: Unknown")
            except Exception as e:
                logger.warning(f"   VRAM: Unable to detect ({e})")

        # å¦‚æœå¯ç”¨äº† worker å¾ªç¯ï¼Œå¯åŠ¨åå°çº¿ç¨‹æ‹‰å–ä»»åŠ¡
        if self.enable_worker_loop:
            self.worker_thread = threading.Thread(target=self._worker_loop, daemon=True)
            self.worker_thread.start()
            logger.info(f"ğŸ”„ Worker loop started (poll_interval={self.poll_interval}s)")
        else:
            logger.info("â¸ï¸  Worker loop disabled, waiting for manual triggers")

    def _worker_loop(self):
        """
        Worker åå°å¾ªç¯ï¼šæŒç»­æ‹‰å–ä»»åŠ¡å¹¶å¤„ç†

        è¿™ä¸ªå¾ªç¯åœ¨åå°çº¿ç¨‹ä¸­è¿è¡Œï¼Œä¸æ–­æ£€æŸ¥æ˜¯å¦æœ‰æ–°ä»»åŠ¡
        ä¸€æ—¦æœ‰ä»»åŠ¡ï¼Œç«‹å³å¤„ç†ï¼Œå¤„ç†å®Œæˆåç»§ç»­å¾ªç¯
        """
        logger.info(f"ğŸ” {self.worker_id} started task polling loop")

        # è®°å½•åˆå§‹è¯Šæ–­ä¿¡æ¯
        try:
            stats = self.task_db.get_queue_stats()
            logger.info(f"ğŸ“Š Initial queue stats: {stats}")
            logger.info(f"ğŸ—ƒï¸  Database path: {self.task_db.db_path}")
        except Exception as e:
            logger.error(f"âŒ Failed to get initial queue stats: {e}")

        loop_count = 0
        last_stats_log = 0
        stats_log_interval = 20  # æ¯20æ¬¡å¾ªç¯è¾“å‡ºä¸€æ¬¡ç»Ÿè®¡ä¿¡æ¯ï¼ˆçº¦10ç§’ï¼‰

        while self.running:
            try:
                loop_count += 1

                # æ‹‰å–ä»»åŠ¡ï¼ˆåŸå­æ“ä½œï¼Œé˜²æ­¢é‡å¤å¤„ç†ï¼‰
                task = self.task_db.get_next_task(worker_id=self.worker_id)

                if task:
                    task_id = task["task_id"]
                    self.current_task_id = task_id
                    logger.info(
                        f"ğŸ“¥ {self.worker_id} pulled task: {task_id} (file: {task.get('file_name', 'unknown')})"
                    )

                    try:
                        # å¤„ç†ä»»åŠ¡
                        self._process_task(task)
                        logger.info(f"âœ… {self.worker_id} completed task: {task_id}")
                    except Exception as e:
                        logger.error(f"âŒ {self.worker_id} failed task {task_id}: {e}")
                        logger.exception(e)
                    finally:
                        self.current_task_id = None
                else:
                    # æ²¡æœ‰ä»»åŠ¡ï¼Œç©ºé—²ç­‰å¾…
                    # å®šæœŸè¾“å‡ºç»Ÿè®¡ä¿¡æ¯ä»¥ä¾¿è¯Šæ–­
                    if loop_count - last_stats_log >= stats_log_interval:
                        try:
                            stats = self.task_db.get_queue_stats()
                            pending = stats.get("pending", 0)
                            processing = stats.get("processing", 0)

                            if pending > 0:
                                logger.warning(
                                    f"âš ï¸  {self.worker_id} polling (loop #{loop_count}): "
                                    f"{pending} pending tasks found but not pulled! "
                                    f"Processing: {processing}, Completed: {stats.get('completed', 0)}, "
                                    f"Failed: {stats.get('failed', 0)}"
                                )
                            elif loop_count % 100 == 0:  # æ¯50ç§’ï¼ˆ100æ¬¡å¾ªç¯ï¼‰è¾“å‡ºä¸€æ¬¡
                                logger.info(
                                    f"ğŸ’¤ {self.worker_id} idle (loop #{loop_count}): "
                                    f"No pending tasks. Queue stats: {stats}"
                                )
                        except Exception as e:
                            logger.error(f"âŒ Failed to get queue stats: {e}")

                        last_stats_log = loop_count

                    time.sleep(self.poll_interval)

            except Exception as e:
                logger.error(f"âŒ Worker loop error (loop #{loop_count}): {e}")
                logger.exception(e)
                time.sleep(self.poll_interval)

    def _process_task(self, task: dict):
        """
        å¤„ç†å•ä¸ªä»»åŠ¡

        Args:
            task: ä»»åŠ¡å­—å…¸ï¼ˆä»æ•°æ®åº“æ‹‰å–ï¼‰
        """
        task_id = task["task_id"]
        file_path = task["file_path"]
        options = json.loads(task.get("options", "{}"))

        try:
            # æ ¹æ® backend é€‰æ‹©å¤„ç†æ–¹å¼ï¼ˆä» task å­—æ®µè¯»å–ï¼Œä¸æ˜¯ä» options è¯»å–ï¼‰
            backend = task.get("backend", "auto")

            # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
            file_ext = Path(file_path).suffix.lower()

            # 0. å¯é€‰ï¼šé¢„å¤„ç† - å»é™¤æ°´å°ï¼ˆä»… PDFï¼Œä½œä¸ºé¢„å¤„ç†æ­¥éª¤ï¼‰
            if file_ext == ".pdf" and options.get("remove_watermark", False) and self.watermark_handler:
                logger.info(f"ğŸ¨ [Preprocessing] Removing watermark from PDF: {file_path}")
                try:
                    cleaned_pdf_path = self._preprocess_remove_watermark(file_path, options)
                    file_path = str(cleaned_pdf_path)  # ä½¿ç”¨å»æ°´å°åçš„æ–‡ä»¶ç»§ç»­å¤„ç†
                    logger.info(f"âœ… [Preprocessing] Watermark removed, continuing with: {file_path}")
                except Exception as e:
                    logger.warning(f"âš ï¸ [Preprocessing] Watermark removal failed: {e}, continuing with original file")
                    # ç»§ç»­ä½¿ç”¨åŸæ–‡ä»¶å¤„ç†

            # ç»Ÿä¸€çš„å¼•æ“è·¯ç”±é€»è¾‘ï¼šä¼˜å…ˆä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„ backendï¼Œå¦åˆ™è‡ªåŠ¨é€‰æ‹©
            result = None  # åˆå§‹åŒ– result

            # 1. ç”¨æˆ·æŒ‡å®šäº†éŸ³é¢‘å¼•æ“
            if backend == "sensevoice":
                if not SENSEVOICE_AVAILABLE:
                    raise ValueError("SenseVoice engine is not available")
                logger.info(f"ğŸ¤ Processing with SenseVoice: {file_path}")
                result = self._process_audio(file_path, options)

            # 3. ç”¨æˆ·æŒ‡å®šäº†è§†é¢‘å¼•æ“
            elif backend == "video":
                if not VIDEO_ENGINE_AVAILABLE:
                    raise ValueError("Video processing engine is not available")
                logger.info(f"ğŸ¬ Processing with video engine: {file_path}")
                result = self._process_video(file_path, options)

            # 4. ç”¨æˆ·æŒ‡å®šäº† PaddleOCR-VL
            elif backend == "paddleocr-vl":
                if not PADDLEOCR_VL_AVAILABLE:
                    raise ValueError("PaddleOCR-VL engine is not available")
                logger.info(f"ğŸ” Processing with PaddleOCR-VL: {file_path}")
                result = self._process_with_paddleocr_vl(file_path, options)

            # 6. ç”¨æˆ·æŒ‡å®šäº† MinerU Pipeline
            elif backend == "pipeline":
                logger.info(f"ğŸ”§ Processing with MinerU Pipeline: {file_path}")
                result = self._process_with_mineru(file_path, options)

            # 7. auto æ¨¡å¼ï¼šæ ¹æ®æ–‡ä»¶ç±»å‹è‡ªåŠ¨é€‰æ‹©å¼•æ“
            elif backend == "auto":
                # 7.1 æ£€æŸ¥æ˜¯å¦æ˜¯ä¸“ä¸šæ ¼å¼ï¼ˆFASTA, GenBank ç­‰ï¼‰
                if FORMAT_ENGINES_AVAILABLE and FormatEngineRegistry.is_supported(file_path):
                    logger.info(f"ğŸ§¬ [Auto] Processing with format engine: {file_path}")
                    result = self._process_with_format_engine(file_path, options)

                # 7.2 æ£€æŸ¥æ˜¯å¦æ˜¯éŸ³é¢‘æ–‡ä»¶
                elif file_ext in [".wav", ".mp3", ".flac", ".m4a", ".ogg"] and SENSEVOICE_AVAILABLE:
                    logger.info(f"ğŸ¤ [Auto] Processing audio file: {file_path}")
                    result = self._process_audio(file_path, options)

                # 7.3 æ£€æŸ¥æ˜¯å¦æ˜¯è§†é¢‘æ–‡ä»¶
                elif file_ext in [".mp4", ".avi", ".mkv", ".mov", ".flv", ".wmv"] and VIDEO_ENGINE_AVAILABLE:
                    logger.info(f"ğŸ¬ [Auto] Processing video file: {file_path}")
                    result = self._process_video(file_path, options)

                # 7.4 é»˜è®¤ä½¿ç”¨ MinerU Pipeline å¤„ç† PDF/å›¾ç‰‡
                elif file_ext in [".pdf", ".png", ".jpg", ".jpeg"]:
                    logger.info(f"ğŸ”§ [Auto] Processing with MinerU Pipeline: {file_path}")
                    result = self._process_with_mineru(file_path, options)

                # 7.5 å…œåº•ï¼šOffice æ–‡æ¡£/æ–‡æœ¬/HTML ä½¿ç”¨ MarkItDownï¼ˆå¦‚æœå¯ç”¨ï¼‰
                elif (
                    file_ext in [".docx", ".xlsx", ".pptx", ".doc", ".xls", ".ppt", ".html", ".txt", ".csv"]
                    and self.markitdown
                ):
                    logger.info(f"ğŸ“„ [Auto] Processing Office/Text file with MarkItDown: {file_path}")
                    result = self._process_with_markitdown(file_path)

                else:
                    # æ²¡æœ‰åˆé€‚çš„å¤„ç†å™¨
                    supported_formats = "PDF, PNG, JPG (MinerU/PaddleOCR), Audio (SenseVoice), Video, FASTA, GenBank"
                    if self.markitdown:
                        supported_formats += ", Office/Text (MarkItDown)"
                    raise ValueError(
                        f"Unsupported file type: file={file_path}, ext={file_ext}. "
                        f"Supported formats: {supported_formats}"
                    )

            else:
                # 8. å°è¯•ä½¿ç”¨æ ¼å¼å¼•æ“ï¼ˆç”¨æˆ·æ˜ç¡®æŒ‡å®šäº† fasta, genbank ç­‰ï¼‰
                if FORMAT_ENGINES_AVAILABLE:
                    engine = FormatEngineRegistry.get_engine(backend)
                    if engine is not None:
                        logger.info(f"ğŸ§¬ Processing with format engine: {backend}")
                        result = self._process_with_format_engine(file_path, options, engine_name=backend)
                    else:
                        # æœªçŸ¥çš„ backend
                        raise ValueError(
                            f"Unknown backend: {backend}. "
                            f"Supported backends: auto, pipeline, paddleocr-vl, sensevoice, video, fasta, genbank"
                        )
                else:
                    # æ ¼å¼å¼•æ“ä¸å¯ç”¨
                    raise ValueError(
                        f"Unknown backend: {backend}. "
                        f"Supported backends: auto, pipeline, paddleocr-vl, sensevoice, video"
                    )

            # æ£€æŸ¥ result æ˜¯å¦è¢«æ­£ç¡®èµ‹å€¼
            if result is None:
                raise ValueError(f"No result generated for backend: {backend}, file: {file_path}")

            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå®Œæˆ
            self.task_db.update_task_status(
                task_id=task_id,
                status="completed",
                result_path=result["result_path"],
                error_message=None,
            )

            # æ¸…ç†æ˜¾å­˜ï¼ˆå¦‚æœæ˜¯ GPUï¼‰
            if "cuda" in str(self.device).lower():
                clean_memory()

        except Exception as e:
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤±è´¥
            error_msg = f"{type(e).__name__}: {str(e)}"
            self.task_db.update_task_status(task_id=task_id, status="failed", result_path=None, error_message=error_msg)
            raise

    def _process_with_mineru(self, file_path: str, options: dict) -> dict:
        """
        ä½¿ç”¨ MinerU å¤„ç†æ–‡æ¡£

        æ³¨æ„ï¼šMinerU çš„ do_parse åªæ¥å— PDF æ ¼å¼ï¼Œå›¾ç‰‡éœ€è¦å…ˆè½¬æ¢ä¸º PDF
        """
        import img2pdf

        file_stem = Path(file_path).stem
        file_ext = Path(file_path).suffix.lower()
        output_dir = Path(self.output_dir) / file_stem
        output_dir.mkdir(parents=True, exist_ok=True)

        # è¯»å–æ–‡ä»¶ä¸ºå­—èŠ‚
        with open(file_path, "rb") as f:
            file_bytes = f.read()

        # MinerU çš„ do_parse åªæ”¯æŒ PDF æ ¼å¼
        # å›¾ç‰‡æ–‡ä»¶éœ€è¦å…ˆè½¬æ¢ä¸º PDF
        if file_ext in [".png", ".jpg", ".jpeg"]:
            logger.info("ğŸ–¼ï¸  Converting image to PDF for MinerU processing...")
            try:
                pdf_bytes = img2pdf.convert(file_bytes)
                file_name = f"{file_stem}.pdf"  # ä½¿ç”¨ .pdf æ‰©å±•å
                logger.info(f"âœ… Image converted: {file_name} ({len(pdf_bytes)} bytes)")
            except Exception as e:
                logger.error(f"âŒ Image conversion failed: {e}")
                raise ValueError(f"Failed to convert image to PDF: {e}")
        else:
            # PDF æ–‡ä»¶ç›´æ¥ä½¿ç”¨
            pdf_bytes = file_bytes
            file_name = Path(file_path).name

        # è·å–è¯­è¨€è®¾ç½®
        # MinerU ä¸æ”¯æŒ "auto"ï¼Œé»˜è®¤ä½¿ç”¨ä¸­æ–‡
        lang = options.get("lang", "auto")
        if lang == "auto":
            lang = "ch"
            logger.info("ğŸŒ Language set to 'ch' (MinerU doesn't support 'auto')")

        # è°ƒç”¨ MinerU æ–°ç‰ˆ APIï¼ˆæ‰¹é‡å¤„ç†æ¥å£ï¼‰
        # æ–°ç‰ˆ API æ¥å—åˆ—è¡¨å‚æ•°ï¼Œå³ä½¿åªæœ‰ä¸€ä¸ªæ–‡ä»¶ä¹Ÿè¦ç”¨åˆ—è¡¨
        # output_format æ”¯æŒ: "md", "md_json" (åŒæ—¶è¾“å‡º markdown å’Œ JSON)
        do_parse(
            pdf_file_names=[file_name],  # æ–‡ä»¶ååˆ—è¡¨
            pdf_bytes_list=[pdf_bytes],  # æ–‡ä»¶å­—èŠ‚åˆ—è¡¨
            p_lang_list=[lang],  # è¯­è¨€åˆ—è¡¨
            output_dir=str(output_dir),  # è¾“å‡ºç›®å½•
            output_format="md_json",  # åŒæ—¶è¾“å‡º Markdown å’Œ JSON
            end_page_id=options.get("end_page_id"),
            layout_mode=options.get("layout_mode", True),
            formula_enable=options.get("formula_enable", True),
            table_enable=options.get("table_enable", True),
        )

        # MinerU æ–°ç‰ˆè¾“å‡ºç»“æ„: {output_dir}/{file_name}/auto/{file_stem}.md
        # é€’å½’æŸ¥æ‰¾ markdown æ–‡ä»¶å’Œ JSON æ–‡ä»¶
        md_files = list(output_dir.rglob("*.md"))

        if md_files:
            # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„ md æ–‡ä»¶
            md_file = md_files[0]
            logger.info(f"âœ… Found MinerU output: {md_file}")
            content = md_file.read_text(encoding="utf-8")

            # è¿”å›å®é™…çš„è¾“å‡ºç›®å½•ï¼ˆåŒ…å« auto/ å­ç›®å½•ï¼‰
            actual_output_dir = md_file.parent

            # æŸ¥æ‰¾ JSON æ–‡ä»¶
            # MinerU è¾“å‡ºçš„ JSON æ–‡ä»¶æ ¼å¼: {filename}_content_list.json, {filename}_middle.json, {filename}_model.json
            # æˆ‘ä»¬ä¸»è¦å…³æ³¨ content_list.jsonï¼ˆåŒ…å«ç»“æ„åŒ–å†…å®¹ï¼‰
            json_files = [
                f
                for f in actual_output_dir.rglob("*.json")
                if "_content_list.json" in f.name and not f.parent.name.startswith("page_")
            ]

            result = {
                "result_path": str(actual_output_dir),  # è¿”å›åŒ…å«æ‰€æœ‰è¾“å‡ºçš„ç›®å½•
                "content": content,
            }

            # å¦‚æœæ‰¾åˆ° JSON æ–‡ä»¶ï¼Œä¹Ÿè¯»å–å®ƒ
            if json_files:
                json_file = json_files[0]
                logger.info(f"âœ… Found MinerU JSON output: {json_file}")
                try:
                    with open(json_file, "r", encoding="utf-8") as f:
                        json_content = json.load(f)
                    result["json_path"] = str(json_file)
                    result["json_content"] = json_content
                except Exception as e:
                    logger.warning(f"âš ï¸  Failed to load JSON: {e}")
            else:
                logger.info("â„¹ï¸  No JSON output found (MinerU may not generate it by default)")

            return result
        else:
            # å¦‚æœæ‰¾ä¸åˆ° md æ–‡ä»¶ï¼Œåˆ—å‡ºè¾“å‡ºç›®å½•å†…å®¹ä»¥ä¾¿è°ƒè¯•
            logger.error("âŒ MinerU output directory structure:")
            for item in output_dir.rglob("*"):
                logger.error(f"   {item}")
            raise FileNotFoundError(f"MinerU output not found in: {output_dir}")

    def _process_with_markitdown(self, file_path: str) -> dict:
        """ä½¿ç”¨ MarkItDown å¤„ç† Office æ–‡æ¡£"""
        if not self.markitdown:
            raise RuntimeError("MarkItDown is not available")

        # å¤„ç†æ–‡ä»¶
        result = self.markitdown.convert(file_path)

        # ä¿å­˜ç»“æœ
        output_file = Path(self.output_dir) / f"{Path(file_path).stem}_markitdown.md"
        output_file.write_text(result.text_content, encoding="utf-8")

        return {"result_path": str(output_file), "content": result.text_content}

    def _process_with_paddleocr_vl(self, file_path: str, options: dict) -> dict:
        """ä½¿ç”¨ PaddleOCR-VL å¤„ç†å›¾ç‰‡æˆ– PDF"""
        # å»¶è¿ŸåŠ è½½ PaddleOCR-VLï¼ˆå•ä¾‹æ¨¡å¼ï¼‰
        if self.paddleocr_vl_engine is None:
            from paddleocr_vl import PaddleOCRVLEngine

            # PaddleOCRVLEngine ä¸æ¥å—å‚æ•°ï¼Œå†…éƒ¨è‡ªåŠ¨ç®¡ç†è®¾å¤‡
            self.paddleocr_vl_engine = PaddleOCRVLEngine()
            logger.info("âœ… PaddleOCR-VL engine loaded (singleton)")

        # è®¾ç½®è¾“å‡ºç›®å½•
        output_dir = Path(self.output_dir) / Path(file_path).stem
        output_dir.mkdir(parents=True, exist_ok=True)

        # å¤„ç†æ–‡ä»¶ï¼ˆparse æ–¹æ³•éœ€è¦ output_pathï¼‰
        result = self.paddleocr_vl_engine.parse(file_path, output_path=str(output_dir))

        # è¿”å›ç»“æœ
        return {"result_path": str(output_dir), "content": result.get("markdown", "")}

    def _process_audio(self, file_path: str, options: dict) -> dict:
        """ä½¿ç”¨ SenseVoice å¤„ç†éŸ³é¢‘æ–‡ä»¶"""
        # å»¶è¿ŸåŠ è½½ SenseVoiceï¼ˆå•ä¾‹æ¨¡å¼ï¼‰
        if self.sensevoice_engine is None:
            from audio_engines import SenseVoiceEngine

            self.sensevoice_engine = SenseVoiceEngine(device=self.device)
            logger.info("âœ… SenseVoice engine loaded (singleton)")

        # å¤„ç†éŸ³é¢‘
        result = self.sensevoice_engine.transcribe(file_path, language=options.get("lang", "auto"))

        # ä¿å­˜ç»“æœ
        output_file = Path(self.output_dir) / f"{Path(file_path).stem}_transcription.txt"
        output_file.write_text(result["text"], encoding="utf-8")

        return {"result_path": str(output_file), "content": result["text"]}

    def _process_video(self, file_path: str, options: dict) -> dict:
        """ä½¿ç”¨è§†é¢‘å¤„ç†å¼•æ“å¤„ç†è§†é¢‘æ–‡ä»¶"""
        # å»¶è¿ŸåŠ è½½è§†é¢‘å¼•æ“ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰
        if self.video_engine is None:
            from video_engines import VideoProcessingEngine

            self.video_engine = VideoProcessingEngine(device=self.device, output_dir=self.output_dir)
            logger.info("âœ… Video processing engine loaded (singleton)")

        # å¤„ç†è§†é¢‘
        result = self.video_engine.process_video(
            video_path=file_path,
            extract_keyframes=options.get("extract_keyframes", True),
            transcribe_audio=options.get("transcribe_audio", True),
            keyframe_interval=options.get("keyframe_interval", 30),
            language=options.get("lang", "auto"),
        )

        # ä¿å­˜ç»“æœï¼ˆMarkdown æ ¼å¼ï¼‰
        output_file = Path(self.output_dir) / f"{Path(file_path).stem}_video_analysis.md"
        output_file.write_text(result["markdown"], encoding="utf-8")

        return {"result_path": str(output_file), "content": result["markdown"]}

    def _preprocess_remove_watermark(self, file_path: str, options: dict) -> Path:
        """
        é¢„å¤„ç†ï¼šå»é™¤ PDF æ°´å°

        è¿™æ˜¯ä¸€ä¸ªå¯é€‰çš„é¢„å¤„ç†æ­¥éª¤ï¼Œå»é™¤æ°´å°åçš„æ–‡ä»¶ä¼šè¢«åç»­çš„è§£æå¼•æ“å¤„ç†

        è¿”å›ï¼š
            å»é™¤æ°´å°åçš„ PDF è·¯å¾„

        æ”¯æŒçš„ options å‚æ•°ï¼š
            - auto_detect: æ˜¯å¦è‡ªåŠ¨æ£€æµ‹ PDF ç±»å‹ï¼ˆé»˜è®¤ Trueï¼‰
            - force_scanned: å¼ºåˆ¶ä½¿ç”¨æ‰«æä»¶æ¨¡å¼ï¼ˆé»˜è®¤ Falseï¼‰
            - remove_text: æ˜¯å¦åˆ é™¤æ–‡æœ¬å¯¹è±¡ï¼ˆå¯ç¼–è¾‘ PDFï¼Œé»˜è®¤ Trueï¼‰
            - remove_images: æ˜¯å¦åˆ é™¤å›¾ç‰‡å¯¹è±¡ï¼ˆå¯ç¼–è¾‘ PDFï¼Œé»˜è®¤ Trueï¼‰
            - remove_annotations: æ˜¯å¦åˆ é™¤æ³¨é‡Šï¼ˆå¯ç¼–è¾‘ PDFï¼Œé»˜è®¤ Trueï¼‰
            - keywords: æ–‡æœ¬å…³é”®è¯åˆ—è¡¨ï¼ˆå¯ç¼–è¾‘ PDFï¼Œåªåˆ é™¤åŒ…å«è¿™äº›å…³é”®è¯çš„æ–‡æœ¬ï¼‰
            - dpi: è½¬æ¢åˆ†è¾¨ç‡ï¼ˆæ‰«æä»¶ PDFï¼Œé»˜è®¤ 200ï¼‰
            - conf_threshold: YOLO ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆæ‰«æä»¶ PDFï¼Œé»˜è®¤ 0.35ï¼‰
            - dilation: æ©ç è†¨èƒ€ï¼ˆæ‰«æä»¶ PDFï¼Œé»˜è®¤ 10ï¼‰
        """
        if not self.watermark_handler:
            raise RuntimeError("Watermark removal is not available (CUDA required)")

        # è®¾ç½®è¾“å‡ºè·¯å¾„
        output_file = Path(self.output_dir) / f"{Path(file_path).stem}_no_watermark.pdf"

        # æ„å»ºå‚æ•°å­—å…¸ï¼ˆåªä¼ é€’å®é™…æä¾›çš„å‚æ•°ï¼‰
        kwargs = {}

        # é€šç”¨å‚æ•°
        if "auto_detect" in options:
            kwargs["auto_detect"] = options["auto_detect"]
        if "force_scanned" in options:
            kwargs["force_scanned"] = options["force_scanned"]

        # å¯ç¼–è¾‘ PDF å‚æ•°
        if "remove_text" in options:
            kwargs["remove_text"] = options["remove_text"]
        if "remove_images" in options:
            kwargs["remove_images"] = options["remove_images"]
        if "remove_annotations" in options:
            kwargs["remove_annotations"] = options["remove_annotations"]
        if "watermark_keywords" in options:
            kwargs["keywords"] = options["watermark_keywords"]

        # æ‰«æä»¶ PDF å‚æ•°
        if "watermark_dpi" in options:
            kwargs["dpi"] = options["watermark_dpi"]
        if "watermark_conf_threshold" in options:
            kwargs["conf_threshold"] = options["watermark_conf_threshold"]
        if "watermark_dilation" in options:
            kwargs["dilation"] = options["watermark_dilation"]

        # å»é™¤æ°´å°ï¼ˆè¿”å›è¾“å‡ºè·¯å¾„ï¼‰
        cleaned_pdf_path = self.watermark_handler.remove_watermark(
            input_path=file_path, output_path=str(output_file), **kwargs
        )

        return cleaned_pdf_path

    def _process_with_format_engine(self, file_path: str, options: dict, engine_name: Optional[str] = None) -> dict:
        """
        ä½¿ç”¨æ ¼å¼å¼•æ“å¤„ç†ä¸“ä¸šé¢†åŸŸæ ¼å¼æ–‡ä»¶

        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            options: å¤„ç†é€‰é¡¹
            engine_name: æŒ‡å®šçš„å¼•æ“åç§°ï¼ˆå¦‚ fasta, genbankï¼‰ï¼Œä¸º None æ—¶è‡ªåŠ¨é€‰æ‹©
        """
        # è·å–è¯­è¨€è®¾ç½®
        lang = options.get("language", "en")

        # æ ¹æ®æŒ‡å®šçš„å¼•æ“åç§°æˆ–æ–‡ä»¶æ‰©å±•åé€‰æ‹©å¼•æ“
        if engine_name:
            # ç”¨æˆ·æ˜ç¡®æŒ‡å®šäº†å¼•æ“
            engine = FormatEngineRegistry.get_engine(engine_name)
            if engine is None:
                raise ValueError(f"Format engine '{engine_name}' not found or not registered")

            # éªŒè¯æ–‡ä»¶æ˜¯å¦é€‚åˆè¯¥å¼•æ“
            if not engine.validate_file(file_path):
                raise ValueError(
                    f"File '{file_path}' is not supported by '{engine_name}' engine. "
                    f"Supported extensions: {', '.join(engine.SUPPORTED_EXTENSIONS)}"
                )

            # ä½¿ç”¨æŒ‡å®šå¼•æ“å¤„ç†
            result = engine.parse(file_path, options={"language": lang})
        else:
            # è‡ªåŠ¨é€‰æ‹©å¼•æ“ï¼ˆæ ¹æ®æ–‡ä»¶æ‰©å±•åï¼‰
            engine = FormatEngineRegistry.get_engine_by_extension(file_path)
            if engine is None:
                raise ValueError(f"No format engine available for file: {file_path}")

            result = engine.parse(file_path, options={"language": lang})

        # ä¸ºæ¯ä¸ªä»»åŠ¡åˆ›å»ºä¸“å±è¾“å‡ºç›®å½•ï¼ˆä¸å…¶ä»–å¼•æ“ä¿æŒä¸€è‡´ï¼‰
        output_dir = Path(self.output_dir) / Path(file_path).stem
        output_dir.mkdir(parents=True, exist_ok=True)

        # ä¿å­˜ç»“æœï¼ˆä¸å…¶ä»–å¼•æ“ä¿æŒä¸€è‡´çš„å‘½åè§„èŒƒï¼‰
        # ä¸»ç»“æœæ–‡ä»¶ï¼šresult.md å’Œ result.json
        output_file = output_dir / "result.md"
        output_file.write_text(result["markdown"], encoding="utf-8")
        logger.info("ğŸ“„ Main result saved: result.md")

        # å¤‡ä»½æ–‡ä»¶ï¼šä½¿ç”¨åŸå§‹æ–‡ä»¶åï¼ˆä¾¿äºè°ƒè¯•ï¼‰
        backup_md_file = output_dir / f"{Path(file_path).stem}_{result['format']}.md"
        backup_md_file.write_text(result["markdown"], encoding="utf-8")
        logger.info(f"ğŸ“„ Backup saved: {backup_md_file.name}")

        # ä¹Ÿä¿å­˜ JSON ç»“æ„åŒ–æ•°æ®
        json_file = output_dir / "result.json"
        json_file.write_text(json.dumps(result["json_content"], indent=2, ensure_ascii=False), encoding="utf-8")
        logger.info("ğŸ“„ Main JSON saved: result.json")

        # å¤‡ä»½ JSON æ–‡ä»¶
        backup_json_file = output_dir / f"{Path(file_path).stem}_{result['format']}.json"
        backup_json_file.write_text(json.dumps(result["json_content"], indent=2, ensure_ascii=False), encoding="utf-8")
        logger.info(f"ğŸ“„ Backup JSON saved: {backup_json_file.name}")

        return {
            "result_path": str(output_dir),  # è¿”å›ä»»åŠ¡ä¸“å±ç›®å½•
            "content": result["content"],
            "json_path": str(json_file),
            "json_content": result["json_content"],
        }

    def decode_request(self, request):
        """
        è§£ç è¯·æ±‚

        LitServe ä¼šè°ƒç”¨è¿™ä¸ªæ–¹æ³•æ¥è§£æè¯·æ±‚
        æˆ‘ä»¬çš„è¯·æ±‚æ ¼å¼: {"action": "health" | "poll"}
        """
        return request.get("action", "health")

    def predict(self, action):
        """
        å¤„ç†è¯·æ±‚

        Args:
            action: è¯·æ±‚åŠ¨ä½œ
                - "health": å¥åº·æ£€æŸ¥
                - "poll": æ‰‹åŠ¨æ‹‰å–ä»»åŠ¡ï¼ˆå½“ worker loop ç¦ç”¨æ—¶ï¼‰

        Returns:
            å“åº”å­—å…¸
        """
        if action == "health":
            # å¥åº·æ£€æŸ¥
            vram_gb = None
            if "cuda" in str(self.device).lower():
                try:
                    vram_gb = get_vram(self.device.split(":")[-1])
                except Exception:
                    pass

            return {
                "status": "healthy",
                "worker_id": self.worker_id,
                "device": str(self.device),
                "vram_gb": vram_gb,
                "running": self.running,
                "current_task": self.current_task_id,
                "worker_loop_enabled": self.enable_worker_loop,
            }

        elif action == "poll":
            # æ‰‹åŠ¨æ‹‰å–ä»»åŠ¡ï¼ˆç”¨äºæµ‹è¯•æˆ–ç¦ç”¨ worker loop æ—¶ï¼‰
            if self.enable_worker_loop:
                return {
                    "status": "skipped",
                    "message": "Worker is in auto-loop mode, manual polling is disabled",
                    "worker_id": self.worker_id,
                }

            task = self.task_db.pull_task()
            if task:
                task_id = task["task_id"]
                logger.info(f"ğŸ“¥ {self.worker_id} manually pulled task: {task_id}")

                try:
                    self._process_task(task)
                    logger.info(f"âœ… {self.worker_id} completed task: {task_id}")

                    return {"status": "completed", "task_id": task["task_id"], "worker_id": self.worker_id}
                except Exception as e:
                    return {
                        "status": "failed",
                        "task_id": task["task_id"],
                        "error": str(e),
                        "worker_id": self.worker_id,
                    }
            else:
                # Worker å¾ªç¯æ¨¡å¼ï¼šè¿”å›çŠ¶æ€ä¿¡æ¯
                return {
                    "status": "auto_mode",
                    "message": "Worker is running in auto-loop mode, tasks are processed automatically",
                    "worker_id": self.worker_id,
                    "worker_running": self.running,
                }

        else:
            return {
                "status": "error",
                "message": f'Invalid action: {action}. Use "health" or "poll".',
                "worker_id": self.worker_id,
            }

    def encode_response(self, response):
        """ç¼–ç å“åº”"""
        return response

    def teardown(self):
        """æ¸…ç†èµ„æºï¼ˆWorker å…³é—­æ—¶è°ƒç”¨ï¼‰"""
        # è·å– worker_idï¼ˆå¯èƒ½åœ¨ setup å¤±è´¥æ—¶æœªåˆå§‹åŒ–ï¼‰
        worker_id = getattr(self, "worker_id", "unknown")

        logger.info(f"ğŸ›‘ Worker {worker_id} shutting down...")

        # è®¾ç½® running æ ‡å¿—ï¼ˆå¦‚æœå·²åˆå§‹åŒ–ï¼‰
        if hasattr(self, "running"):
            self.running = False

        # ç­‰å¾… worker çº¿ç¨‹ç»“æŸ
        if hasattr(self, "worker_thread") and self.worker_thread.is_alive():
            self.worker_thread.join(timeout=5)

        logger.info(f"âœ… Worker {worker_id} stopped")


def start_litserve_workers(
    output_dir=None,  # é»˜è®¤ä»ç¯å¢ƒå˜é‡è¯»å–
    accelerator="auto",
    devices="auto",
    workers_per_device=1,
    port=9000,
    poll_interval=0.5,
    enable_worker_loop=True,
):
    """
    å¯åŠ¨ LitServe Worker Pool

    Args:
        output_dir: è¾“å‡ºç›®å½•
        accelerator: åŠ é€Ÿå™¨ç±»å‹ (auto/cuda/cpu/mps)
        devices: ä½¿ç”¨çš„è®¾å¤‡ (auto/[0,1,2])
        workers_per_device: æ¯ä¸ª GPU çš„ worker æ•°é‡
        port: æœåŠ¡ç«¯å£
        poll_interval: Worker æ‹‰å–ä»»åŠ¡çš„é—´éš”ï¼ˆç§’ï¼‰
        enable_worker_loop: æ˜¯å¦å¯ç”¨ worker è‡ªåŠ¨å¾ªç¯æ‹‰å–ä»»åŠ¡
    """
    # å¦‚æœæ²¡æœ‰æŒ‡å®šè¾“å‡ºç›®å½•ï¼Œä»ç¯å¢ƒå˜é‡è¯»å–
    if output_dir is None:
        output_dir = os.getenv("OUTPUT_PATH", "/app/output")

    logger.info("=" * 60)
    logger.info("ğŸš€ Starting MinerU Tianshu LitServe Worker Pool")
    logger.info("=" * 60)
    logger.info(f"ğŸ“‚ Output Directory: {output_dir}")
    logger.info(f"ğŸ® Accelerator: {accelerator}")
    logger.info(f"ğŸ’¾ Devices: {devices}")
    logger.info(f"ğŸ‘· Workers per Device: {workers_per_device}")
    logger.info(f"ğŸ”Œ Port: {port}")
    logger.info(f"ğŸ”„ Worker Loop: {'Enabled' if enable_worker_loop else 'Disabled'}")
    if enable_worker_loop:
        logger.info(f"â±ï¸  Poll Interval: {poll_interval}s")
    logger.info("=" * 60)

    # åˆ›å»º LitServe æœåŠ¡å™¨
    # æ³¨æ„ï¼šLitAPI ä¸æ”¯æŒ __init__ å‚æ•°ï¼Œéœ€è¦é€šè¿‡ç±»å±æ€§ä¼ é€’é…ç½®
    MinerUWorkerAPI._output_dir = output_dir
    MinerUWorkerAPI._poll_interval = poll_interval
    MinerUWorkerAPI._enable_worker_loop = enable_worker_loop

    api = MinerUWorkerAPI()
    server = ls.LitServer(
        api,
        accelerator=accelerator,
        devices=devices,
        workers_per_device=workers_per_device,
        timeout=False,  # ä¸è®¾ç½®è¶…æ—¶
    )

    # æ³¨å†Œä¼˜é›…å…³é—­å¤„ç†å™¨
    def graceful_shutdown(signum=None, frame=None):
        """å¤„ç†å…³é—­ä¿¡å·ï¼Œä¼˜é›…åœ°åœæ­¢ worker"""
        logger.info("ğŸ›‘ Received shutdown signal, gracefully stopping workers...")
        # æ³¨æ„ï¼šLitServe ä¼šä¸ºæ¯ä¸ªè®¾å¤‡åˆ›å»ºå¤šä¸ª worker å®ä¾‹
        # è¿™é‡Œçš„ api åªæ˜¯æ¨¡æ¿ï¼Œå®é™…çš„ worker å®ä¾‹ç”± LitServe ç®¡ç†
        # teardown ä¼šåœ¨æ¯ä¸ª worker è¿›ç¨‹ä¸­è¢«è°ƒç”¨
        if hasattr(api, "teardown"):
            api.teardown()
        sys.exit(0)

    # æ³¨å†Œä¿¡å·å¤„ç†å™¨ï¼ˆCtrl+C ç­‰ï¼‰
    signal.signal(signal.SIGINT, graceful_shutdown)
    signal.signal(signal.SIGTERM, graceful_shutdown)

    # æ³¨å†Œ atexit å¤„ç†å™¨ï¼ˆæ­£å¸¸é€€å‡ºæ—¶è°ƒç”¨ï¼‰
    atexit.register(lambda: api.teardown() if hasattr(api, "teardown") else None)

    logger.info("âœ… LitServe worker pool initialized")
    logger.info(f"ğŸ“¡ Listening on: http://0.0.0.0:{port}/predict")
    if enable_worker_loop:
        logger.info("ğŸ” Workers will continuously poll and process tasks")
    else:
        logger.info("ğŸ”„ Workers will wait for scheduler triggers")
    logger.info("=" * 60)

    # å¯åŠ¨æœåŠ¡å™¨
    # æ³¨æ„ï¼šLitServe å†…ç½® MCP å·²é€šè¿‡ monkeypatch å®Œå…¨ç¦ç”¨ï¼ˆæˆ‘ä»¬æœ‰ç‹¬ç«‹çš„ MCP Serverï¼‰
    server.run(port=port, generate_client_file=False)


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="MinerU Tianshu LitServe Worker Pool")
    parser.add_argument(
        "--output-dir",
        type=str,
        default=None,
        help="Output directory for processed files (default: from OUTPUT_PATH env or /app/output)",
    )
    parser.add_argument("--port", type=int, default=9000, help="Server port (default: 9000)")
    parser.add_argument(
        "--accelerator",
        type=str,
        default="auto",
        choices=["auto", "cuda", "cpu", "mps"],
        help="Accelerator type (default: auto)",
    )
    parser.add_argument("--workers-per-device", type=int, default=1, help="Number of workers per device (default: 1)")
    parser.add_argument("--devices", type=str, default="auto", help="Devices to use, comma-separated (default: auto)")
    parser.add_argument(
        "--poll-interval", type=float, default=0.5, help="Worker poll interval in seconds (default: 0.5)"
    )
    parser.add_argument(
        "--disable-worker-loop",
        action="store_true",
        help="Disable automatic worker loop (workers will wait for manual triggers)",
    )

    args = parser.parse_args()

    # å¤„ç† devices å‚æ•°
    devices = args.devices
    if devices != "auto":
        try:
            devices = [int(d.strip()) for d in devices.split(",")]
        except ValueError:
            logger.error(f"âŒ Invalid devices format: {devices}. Use comma-separated integers (e.g., '0,1,2')")
            sys.exit(1)

    start_litserve_workers(
        output_dir=args.output_dir,
        accelerator=args.accelerator,
        devices=devices,
        workers_per_device=args.workers_per_device,
        port=args.port,
        poll_interval=args.poll_interval,
        enable_worker_loop=not args.disable_worker_loop,
    )

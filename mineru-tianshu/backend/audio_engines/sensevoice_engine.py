"""
SenseVoice è¯­éŸ³è¯†åˆ«å¼•æ“
åŸºäºé˜¿é‡Œè¾¾æ‘©é™¢çš„ SenseVoiceSmall æ¨¡å‹
æ”¯æŒï¼š
- å¤šè¯­è¨€è¯†åˆ«ï¼ˆä¸­æ–‡ã€è‹±æ–‡ã€æ—¥æ–‡ã€éŸ©æ–‡ç­‰ï¼‰
- è¯´è¯äººè¯†åˆ«ï¼ˆSpeaker Diarizationï¼‰
- æƒ…æ„Ÿè¯†åˆ«
- æ—¶é—´æˆ³å¯¹é½
"""

import json
from pathlib import Path
from typing import Dict, Any, List, Optional
from threading import Lock
from loguru import logger


class SenseVoiceEngine:
    """
    SenseVoice è¯­éŸ³è¯†åˆ«å¼•æ“ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰

    ç‰¹æ€§ï¼š
    - åŸºäº FunASR æ¡†æ¶
    - æ”¯æŒå¤šè¯­è¨€è‡ªåŠ¨è¯†åˆ«
    - æ”¯æŒè¯´è¯äººåˆ†ç¦»
    - GPU åŠ é€Ÿ
    """

    _instance: Optional["SenseVoiceEngine"] = None
    _lock = Lock()
    _model = None
    _initialized = False

    def __new__(cls, *args, **kwargs):
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
        return cls._instance

    def __init__(self, model_dir: str = "iic/SenseVoiceSmall", cache_dir: Optional[str] = None):
        """
        åˆå§‹åŒ– SenseVoice å¼•æ“ï¼ˆåªæ‰§è¡Œä¸€æ¬¡ï¼‰

        Args:
            model_dir: æ¨¡å‹è·¯å¾„æˆ–ModelScopeæ¨¡å‹ID
            cache_dir: æ¨¡å‹ç¼“å­˜ç›®å½•
        """
        if self._initialized:
            return

        with self._lock:
            if self._initialized:
                return

            self.model_dir = model_dir

            # é»˜è®¤ç¼“å­˜ç›®å½•ï¼šé¡¹ç›®æ ¹ç›®å½•/models/sensevoice
            if cache_dir is None:
                project_root = Path(__file__).parent.parent.parent
                self.cache_dir = str(project_root / "models" / "sensevoice")
            else:
                self.cache_dir = cache_dir

            # ç¡®ä¿ç¼“å­˜ç›®å½•å­˜åœ¨
            Path(self.cache_dir).mkdir(parents=True, exist_ok=True)

            self._initialized = True

            logger.info("ğŸ”§ SenseVoice Engine initialized")
            logger.info(f"   Model: {self.model_dir}")
            logger.info(f"   Cache: {self.cache_dir}")

    def _load_model(self):
        """å»¶è¿ŸåŠ è½½æ¨¡å‹"""
        if self._model is not None:
            return self._model

        with self._lock:
            if self._model is not None:
                return self._model

            logger.info("=" * 60)
            logger.info("ğŸ“¥ Loading SenseVoice Model...")
            logger.info("=" * 60)

            try:
                from funasr import AutoModel

                logger.info(f"ğŸ¤– Loading model from: {self.model_dir}")

                # åŠ è½½ SenseVoice æ¨¡å‹
                self._model = AutoModel(
                    model=self.model_dir,
                    trust_remote_code=True,
                    remote_code="./model.py",
                    vad_model="fsmn-vad",  # è¯­éŸ³æ´»åŠ¨æ£€æµ‹
                    vad_kwargs={"max_single_segment_time": 30000},  # æœ€å¤§å•æ®µæ—¶é•¿30ç§’
                    device="cuda:0",  # ä½¿ç”¨GPU
                )

                logger.info("=" * 60)
                logger.info("âœ… SenseVoice Model loaded successfully!")
                logger.info("   Features:")
                logger.info("   - Multi-language ASR (zh/en/ja/ko/yue)")
                logger.info("   - Emotion Recognition")
                logger.info("   - Speaker Diarization")
                logger.info("   - Timestamp Alignment")
                logger.info("=" * 60)

                return self._model

            except Exception as e:
                logger.error("=" * 80)
                logger.error("âŒ æ¨¡å‹åŠ è½½å¤±è´¥:")
                logger.error(f"   é”™è¯¯ç±»å‹: {type(e).__name__}")
                logger.error(f"   é”™è¯¯ä¿¡æ¯: {e}")
                logger.error("")
                logger.error("ğŸ’¡ æ’æŸ¥å»ºè®®:")
                logger.error("   1. å®‰è£… FunASR:")
                logger.error("      pip install funasr")
                logger.error("   2. æ£€æŸ¥ç½‘ç»œè¿æ¥ï¼ˆé¦–æ¬¡ä½¿ç”¨éœ€è¦ä¸‹è½½æ¨¡å‹ï¼‰")
                logger.error("   3. æ£€æŸ¥ GPU å¯ç”¨æ€§")
                logger.error("   4. æ¨¡å‹ä¼šè‡ªåŠ¨ä» ModelScope ä¸‹è½½")
                logger.error("=" * 80)

                import traceback

                logger.debug("å®Œæ•´å †æ ˆè·Ÿè¸ª:")
                logger.debug(traceback.format_exc())

                raise

    def parse(
        self, audio_path: str, output_path: str, language: str = "auto", use_itn: bool = True, **kwargs
    ) -> Dict[str, Any]:
        """
        è¯­éŸ³è¯†åˆ«

        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            output_path: è¾“å‡ºç›®å½•
            language: è¯­è¨€ä»£ç  (auto/zh/en/ja/ko/yue)
            use_itn: æ˜¯å¦ä½¿ç”¨é€†æ–‡æœ¬å½’ä¸€åŒ–ï¼ˆæ•°å­—ã€æ—¥æœŸç­‰ï¼‰
            **kwargs: å…¶ä»–å‚æ•°

        Returns:
            è§£æç»“æœï¼ˆJSONæ ¼å¼ï¼ŒåŒ…å«è¯´è¯äººä¿¡æ¯ï¼‰
        """
        audio_path = Path(audio_path)
        output_path = Path(output_path)
        output_path.mkdir(parents=True, exist_ok=True)

        logger.info(f"ğŸ™ï¸  SenseVoice processing: {audio_path.name}")
        logger.info(f"   Language: {language}")

        # åŠ è½½æ¨¡å‹
        model = self._load_model()

        # æ‰§è¡Œæ¨ç†
        try:
            logger.info("ğŸš€ å¼€å§‹è¯­éŸ³è¯†åˆ«...")

            # FunASR æ¨ç†
            # languageå‚æ•°æ˜ å°„: auto, zh, en, ja, ko, yue, nospeech
            result = model.generate(
                input=str(audio_path),
                cache={},
                language=language,
                use_itn=use_itn,
                batch_size=60,
                merge_vad=True,  # åˆå¹¶VADç»“æœ
                merge_length_s=15,  # åˆå¹¶é•¿åº¦
            )

            logger.info("âœ… SenseVoice completed")

            # è§£æç»“æœ
            parsed_result = self._parse_result(result, audio_path)

            # ç”Ÿæˆ Markdown
            markdown_content = self._generate_markdown(parsed_result)

            # ä¿å­˜ä¸ºç»Ÿä¸€çš„ content.mdï¼ˆä¸»ç»“æœï¼‰
            content_md_file = output_path / "content.md"
            content_md_file.write_text(markdown_content, encoding="utf-8")
            logger.info("ğŸ“„ Main result saved: content.md")

            # åŒæ—¶ä¿ç•™åŸå§‹å‘½åçš„æ–‡ä»¶ï¼ˆç”¨äºè°ƒè¯•/å¤‡ä»½ï¼‰
            original_md_file = output_path / f"{audio_path.stem}.md"
            original_md_file.write_text(markdown_content, encoding="utf-8")
            logger.info(f"ğŸ“„ Backup saved: {original_md_file.name}")

            # ä¿å­˜ä¸ºç»Ÿä¸€çš„ content.jsonï¼ˆä¸»ç»“æœï¼‰
            content_json_file = output_path / "content.json"
            with open(content_json_file, "w", encoding="utf-8") as f:
                json.dump(parsed_result, f, ensure_ascii=False, indent=2)
            logger.info("ğŸ“„ Main JSON saved: content.json")

            # åŒæ—¶ä¿ç•™åŸå§‹å‘½åçš„æ–‡ä»¶ï¼ˆç”¨äºè°ƒè¯•/å¤‡ä»½ï¼‰
            original_json_file = output_path / f"{audio_path.stem}.json"
            with open(original_json_file, "w", encoding="utf-8") as f:
                json.dump(parsed_result, f, ensure_ascii=False, indent=2)
            logger.info(f"ğŸ“„ Backup JSON saved: {original_json_file.name}")

            return {
                "success": True,
                "output_path": str(output_path),
                "markdown": markdown_content,
                "markdown_file": str(content_md_file),
                "json_file": str(content_json_file),
                "json_data": parsed_result,
                "result": result,  # åŸå§‹ç»“æœ
            }

        except Exception as e:
            logger.error("=" * 80)
            logger.error("âŒ è¯­éŸ³è¯†åˆ«å¤±è´¥:")
            logger.error(f"   é”™è¯¯ç±»å‹: {type(e).__name__}")
            logger.error(f"   é”™è¯¯ä¿¡æ¯: {e}")
            logger.error("=" * 80)

            import traceback

            logger.debug("å®Œæ•´å †æ ˆè·Ÿè¸ª:")
            logger.debug(traceback.format_exc())

            raise

    def _parse_result(self, result: List[Dict], audio_path: Path) -> Dict[str, Any]:
        """
        è§£æ FunASR è¿”å›çš„ç»“æœä¸ºæ ‡å‡†æ ¼å¼

        Args:
            result: FunASR è¿”å›çš„ç»“æœåˆ—è¡¨
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„

        Returns:
            æ ‡å‡†åŒ–çš„ JSON ç»“æœ
        """
        if not result or len(result) == 0:
            logger.warning("âš ï¸  è¯†åˆ«ç»“æœä¸ºç©º")
            return {
                "version": "1.0",
                "type": "audio",
                "source": {"filename": audio_path.name, "file_type": "audio"},
                "content": {"text": "", "segments": []},
            }

        # FunASR è¿”å›çš„æ˜¯åˆ—è¡¨ï¼Œé€šå¸¸åªæœ‰ä¸€ä¸ªå…ƒç´ 
        res = result[0]

        # æå–æ–‡æœ¬ï¼ˆä½¿ç”¨åå¤„ç†çš„æ–‡æœ¬ï¼‰
        full_text = res.get("text", "")

        # æå–åˆ†æ®µä¿¡æ¯
        segments = []

        # ä» text å­—æ®µè§£æï¼ˆSenseVoice è¾“å‡ºæ ¼å¼ï¼‰
        # æ ¼å¼ç¤ºä¾‹ï¼š<|zh|><|NEUTRAL|><|Speech|><|woitn|>å®é™…æ–‡æœ¬å†…å®¹
        raw_segments = res.get("text_segments", [])

        if raw_segments:
            # æœ‰è¯¦ç»†çš„åˆ†æ®µä¿¡æ¯
            for idx, seg in enumerate(raw_segments):
                segment = {
                    "id": idx,
                    "text": seg.get("text", ""),
                    "start": seg.get("start", 0.0) / 1000,  # è½¬ä¸ºç§’
                    "end": seg.get("end", 0.0) / 1000,
                    "speaker": seg.get("speaker", "SPEAKER_00"),  # è¯´è¯äºº
                    "emotion": seg.get("emotion", "NEUTRAL"),  # æƒ…æ„Ÿ
                    "language": seg.get("language", "zh"),  # è¯­è¨€
                }
                segments.append(segment)
        else:
            # ç®€å•æ¨¡å¼ï¼šåªæœ‰å®Œæ•´æ–‡æœ¬
            # å°è¯•è§£ææ ‡ç­¾
            language, emotion, event = self._parse_tags(full_text)

            segments.append(
                {
                    "id": 0,
                    "text": full_text,
                    "start": 0.0,
                    "end": 0.0,
                    "speaker": "SPEAKER_00",
                    "emotion": emotion,
                    "language": language,
                    "event": event,
                }
            )

        # æ£€æµ‹è¯­è¨€
        detected_language = self._detect_language(full_text)

        # ç»Ÿè®¡ä¿¡æ¯
        total_duration = segments[-1]["end"] if segments and segments[-1]["end"] > 0 else 0
        speakers = list(set(seg["speaker"] for seg in segments))

        return {
            "version": "1.0",
            "type": "audio",
            "source": {
                "filename": audio_path.name,
                "file_type": audio_path.suffix[1:],
                "duration": total_duration,
            },
            "metadata": {
                "language": detected_language,
                "speakers": speakers,
                "speaker_count": len(speakers),
                "segment_count": len(segments),
            },
            "content": {"text": full_text, "segments": segments},
        }

    def _parse_tags(self, text: str) -> tuple:
        """
        è§£æ SenseVoice è¾“å‡ºçš„æ ‡ç­¾
        æ ¼å¼ï¼š<|zh|><|NEUTRAL|><|Speech|>å®é™…å†…å®¹

        Returns:
            (language, emotion, event)
        """
        import re

        language = "zh"
        emotion = "NEUTRAL"
        event = "Speech"

        # åŒ¹é…è¯­è¨€æ ‡ç­¾
        lang_match = re.search(r"<\|(zh|en|ja|ko|yue|nospeech)\|>", text)
        if lang_match:
            language = lang_match.group(1)

        # åŒ¹é…æƒ…æ„Ÿæ ‡ç­¾
        emotion_match = re.search(r"<\|(NEUTRAL|HAPPY|ANGRY|SAD)\|>", text)
        if emotion_match:
            emotion = emotion_match.group(1)

        # åŒ¹é…äº‹ä»¶æ ‡ç­¾
        event_match = re.search(r"<\|(Speech|Applause|BGM|Laugh)\|>", text)
        if event_match:
            event = event_match.group(1)

        return language, emotion, event

    def _detect_language(self, text: str) -> str:
        """æ™ºèƒ½è¯­è¨€æ£€æµ‹"""
        import re

        # 1. é¦–å…ˆå°è¯•ä»æ ‡ç­¾ä¸­æå–è¯­è¨€ä¿¡æ¯
        lang_match = re.search(r"<\|(zh|en|ja|ko|yue)\|>", text)
        if lang_match:
            return lang_match.group(1)

        # 2. ç§»é™¤æ‰€æœ‰æ ‡ç­¾åè¿›è¡Œå†…å®¹æ£€æµ‹
        clean_text = re.sub(r"<\|[^|]+\|>", "", text).strip()

        if not clean_text:
            return "unknown"

        # 3. ç»Ÿè®¡å„ç§å­—ç¬¦
        total_chars = len(clean_text)
        chinese_chars = sum(1 for c in clean_text if "\u4e00" <= c <= "\u9fff")
        japanese_chars = sum(1 for c in clean_text if "\u3040" <= c <= "\u309f" or "\u30a0" <= c <= "\u30ff")
        korean_chars = sum(1 for c in clean_text if "\uac00" <= c <= "\ud7af")

        # 4. æ ¹æ®å­—ç¬¦æ¯”ä¾‹åˆ¤æ–­
        if chinese_chars / total_chars > 0.2:
            return "zh"
        elif japanese_chars / total_chars > 0.1:
            return "ja"
        elif korean_chars / total_chars > 0.1:
            return "ko"
        elif all(ord(c) < 128 or c.isspace() for c in clean_text if c.isalnum() or c.isspace()):
            # å…¨æ˜¯ASCIIå­—ç¬¦
            return "en"

        return "auto"

    def _emotion_to_emoji(self, emotion: str) -> str:
        """
        å°†æƒ…æ„Ÿæ ‡ç­¾è½¬æ¢ä¸º emoji

        Args:
            emotion: æƒ…æ„Ÿæ ‡ç­¾ (NEUTRAL/HAPPY/ANGRY/SAD)

        Returns:
            å¯¹åº”çš„ emoji å­—ç¬¦
        """
        emotion_map = {
            "NEUTRAL": "ğŸ˜",
            "HAPPY": "ğŸ˜Š",
            "ANGRY": "ğŸ˜ ",
            "SAD": "ğŸ˜¢",
        }
        return emotion_map.get(emotion.upper(), "")

    def _event_to_emoji(self, event: str) -> str:
        """
        å°†äº‹ä»¶æ ‡ç­¾è½¬æ¢ä¸º emoji

        Args:
            event: äº‹ä»¶æ ‡ç­¾ (Speech/Applause/BGM/Laugh)

        Returns:
            å¯¹åº”çš„ emoji å­—ç¬¦
        """
        event_map = {
            "Speech": "ğŸ’¬",
            "Applause": "ğŸ‘",
            "BGM": "ğŸµ",
            "Laugh": "ğŸ˜„",
        }
        return event_map.get(event, "ğŸ’¬")

    def _clean_text_tags(self, text: str) -> str:
        """
        æ¸…ç†æ–‡æœ¬ä¸­çš„æ ‡ç­¾ï¼Œæ›¿æ¢ä¸º emoji

        Args:
            text: åŸå§‹æ–‡æœ¬ï¼ˆåŒ…å«æ ‡ç­¾ï¼‰

        Returns:
            æ¸…ç†åçš„æ–‡æœ¬ï¼ˆæ ‡ç­¾æ›¿æ¢ä¸º emojiï¼‰
        """
        import re

        # è¯­è¨€æ ‡ç­¾ - ç›´æ¥ç§»é™¤ï¼ˆå·²åœ¨å…ƒæ•°æ®ä¸­æ˜¾ç¤ºï¼‰
        text = re.sub(r"<\|(zh|en|ja|ko|yue|nospeech)\|>", "", text)

        # æƒ…æ„Ÿæ ‡ç­¾ - æ›¿æ¢ä¸º emoji
        def replace_emotion(match):
            emotion = match.group(1)
            emoji = self._emotion_to_emoji(emotion)
            return emoji if emoji else ""

        text = re.sub(r"<\|(NEUTRAL|HAPPY|ANGRY|SAD)\|>", replace_emotion, text)

        # äº‹ä»¶æ ‡ç­¾ - æ›¿æ¢ä¸º emoji
        def replace_event(match):
            event = match.group(1)
            emoji = self._event_to_emoji(event)
            return emoji if emoji else ""

        text = re.sub(r"<\|(Speech|Applause|BGM|Laugh)\|>", replace_event, text)

        # å…¶ä»–æ ‡ç­¾ - ç›´æ¥ç§»é™¤
        text = re.sub(r"<\|[^|]+\|>", "", text)

        # æ¸…ç†å¤šä½™ç©ºæ ¼
        text = " ".join(text.split())

        return text.strip()

    def _generate_markdown(self, parsed_result: Dict[str, Any]) -> str:
        """
        ç”Ÿæˆ Markdown æ ¼å¼çš„è½¬å†™æ–‡æœ¬

        Args:
            parsed_result: è§£æåçš„ç»“æœ

        Returns:
            Markdown æ ¼å¼çš„æ–‡æœ¬
        """
        lines = []

        # æ ‡é¢˜
        lines.append(f"# è¯­éŸ³è½¬å†™ï¼š{parsed_result['source']['filename']}\n")

        # å…ƒä¿¡æ¯
        metadata = parsed_result["metadata"]
        lang_map = {"zh": "ğŸ‡¨ğŸ‡³ ä¸­æ–‡", "en": "ğŸ‡ºğŸ‡¸ è‹±æ–‡", "ja": "ğŸ‡¯ğŸ‡µ æ—¥æ–‡", "ko": "ğŸ‡°ğŸ‡· éŸ©æ–‡", "yue": "ğŸ‡­ğŸ‡° ç²¤è¯­"}
        lang_display = lang_map.get(metadata["language"], metadata["language"])

        lines.append(f"**è¯­è¨€**: {lang_display}")
        lines.append(f"**è¯´è¯äººæ•°**: {metadata['speaker_count']}")
        if metadata.get("speakers"):
            lines.append(f"**è¯´è¯äºº**: {', '.join(metadata['speakers'])}")
        lines.append("")

        # å®Œæ•´æ–‡æœ¬ï¼ˆæ¸…ç†æ ‡ç­¾ï¼‰
        lines.append("## å®Œæ•´æ–‡æœ¬\n")
        clean_text = self._clean_text_tags(parsed_result["content"]["text"])
        lines.append(clean_text)
        lines.append("")

        # åˆ†æ®µæ–‡æœ¬ï¼ˆå§‹ç»ˆæ˜¾ç¤ºï¼Œå› ä¸ºåŒ…å«æƒ…æ„Ÿå’Œäº‹ä»¶ä¿¡æ¯ï¼‰
        segments = parsed_result["content"]["segments"]
        if segments:
            lines.append("## åˆ†æ®µè½¬å†™\n")

            current_speaker = None
            for seg in segments:
                speaker = seg.get("speaker", "SPEAKER_00")
                start_time = seg.get("start", 0)
                text = seg.get("text", "")
                emotion = seg.get("emotion", "")
                event = seg.get("event", "")

                # æ¸…ç†æ–‡æœ¬æ ‡ç­¾
                clean_seg_text = self._clean_text_tags(text)

                # å¦‚æœè¯´è¯äººå˜åŒ–ï¼Œæ·»åŠ åˆ†éš”
                if speaker != current_speaker:
                    current_speaker = speaker
                    lines.append(f"\n**{speaker}**:\n")

                # æ—¶é—´æˆ³æ ¼å¼åŒ–
                timestamp = self._format_timestamp(start_time)

                # æ·»åŠ æƒ…æ„Ÿ emojiï¼ˆå¦‚æœä¸æ˜¯ NEUTRALï¼‰
                emotion_emoji = self._emotion_to_emoji(emotion) if emotion and emotion != "NEUTRAL" else ""
                emotion_tag = f" {emotion_emoji}" if emotion_emoji else ""

                # æ·»åŠ äº‹ä»¶ emoji
                event_emoji = self._event_to_emoji(event) if event else ""
                event_tag = f" {event_emoji}" if event_emoji and event != "Speech" else ""

                lines.append(f"[{timestamp}]{emotion_tag}{event_tag} {clean_seg_text}")

        return "\n".join(lines)

    def _format_timestamp(self, seconds: float) -> str:
        """
        æ ¼å¼åŒ–æ—¶é—´æˆ³

        Args:
            seconds: ç§’æ•°

        Returns:
            æ ¼å¼åŒ–çš„æ—¶é—´å­—ç¬¦ä¸² (HH:MM:SS)
        """
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)

        if hours > 0:
            return f"{hours:02d}:{minutes:02d}:{secs:02d}"
        else:
            return f"{minutes:02d}:{secs:02d}"


# å…¨å±€å•ä¾‹
_engine = None


def get_engine() -> SenseVoiceEngine:
    """è·å–å…¨å±€å¼•æ“å®ä¾‹"""
    global _engine
    if _engine is None:
        _engine = SenseVoiceEngine()
    return _engine

"""
FASTA Format Engine - FASTA æ ¼å¼è§£æå¼•æ“

FASTA æ˜¯ç”Ÿç‰©ä¿¡æ¯å­¦ä¸­æœ€å¸¸ç”¨çš„åºåˆ—æ ¼å¼
ç”¨äºå­˜å‚¨æ ¸é…¸åºåˆ—ï¼ˆDNA/RNAï¼‰æˆ–è›‹ç™½è´¨åºåˆ—

æ ¼å¼ç¤ºä¾‹ï¼š
>åºåˆ—ID|æè¿°ä¿¡æ¯
ATCGATCGATCGATCG
GCTAGCTAGCTAGCTA
>å¦ä¸€ä¸ªåºåˆ—ID|æè¿°
GGGGCCCCAAAATTTT

ä¾èµ–ï¼š
- BioPython: å¿…éœ€ï¼Œç”¨äºå‡†ç¡®è§£æç”Ÿç‰©åºåˆ—
"""

from typing import Dict, List, Optional
from .base import FormatEngine
from .i18n import get_language, SemanticGenerator, CommonSemantics


class FASTAEngine(FormatEngine):
    """FASTA æ ¼å¼è§£æå¼•æ“ï¼ˆåŸºäº BioPythonï¼‰"""

    FORMAT_NAME = "fasta"
    FORMAT_DESCRIPTION = "ç”Ÿç‰©åºåˆ—æ ¼å¼ (DNA/RNA/è›‹ç™½è´¨)"
    SUPPORTED_EXTENSIONS = {".fasta", ".fa", ".fna", ".ffn", ".faa", ".frn", ".fas"}

    def __init__(self):
        super().__init__()

        # å¯¼å…¥ BioPythonï¼ˆå¿…éœ€ï¼‰
        try:
            from Bio import SeqIO
            from Bio.SeqUtils import gc_fraction, molecular_weight
            from Bio.SeqUtils.ProtParam import ProteinAnalysis
            from Bio.Seq import Seq
            from Bio.Data import CodonTable

            self._SeqIO = SeqIO
            self._gc_fraction = gc_fraction
            self._molecular_weight = molecular_weight
            self._ProteinAnalysis = ProteinAnalysis
            self._Seq = Seq
            self._CodonTable = CodonTable

            self.logger.info("âœ… BioPython loaded for FASTA parsing with advanced analysis")
        except ImportError as e:
            self.logger.error("âŒ BioPython is required for FASTA parsing")
            raise ImportError(
                "BioPython is required for FASTA format support. " "Install it with: pip install biopython>=1.80"
            ) from e

    def parse(self, file_path: str, options: Optional[Dict] = None) -> Dict:
        """
        è§£æ FASTA æ–‡ä»¶

        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            options: è§£æé€‰é¡¹
                - max_sequence_preview: åºåˆ—é¢„è§ˆçš„æœ€å¤§é•¿åº¦ï¼ˆé»˜è®¤ 100ï¼‰
                - include_full_sequence: æ˜¯å¦åœ¨ JSON ä¸­åŒ…å«å®Œæ•´åºåˆ—ï¼ˆé»˜è®¤ Trueï¼‰
                - language: è¯­ä¹‰æè¿°è¯­è¨€ ('en' æˆ– 'zh'ï¼Œé»˜è®¤ 'en')

        Returns:
            è§£æç»“æœ
        """
        if not self.validate_file(file_path):
            raise ValueError(f"Unsupported file format: {file_path}")

        # è§£æé€‰é¡¹
        options = options or {}
        max_preview = options.get("max_sequence_preview", 100)
        include_full = options.get("include_full_sequence", True)
        lang_code = options.get("language", "en")

        # è§£æè¯­è¨€å¹¶åˆå§‹åŒ–å›½é™…åŒ–ç»„ä»¶
        lang = get_language(lang_code)
        self.semantic_gen = SemanticGenerator(lang)
        self.common_i18n = CommonSemantics(lang)

        # ä½¿ç”¨ BioPython è§£æ
        sequences = self._parse_with_biopython(file_path)

        # ç”Ÿæˆ Markdown å’Œ JSON
        markdown = self._generate_markdown(sequences, max_preview)
        json_content = self._generate_json(sequences, include_full)
        metadata = self._generate_metadata(sequences)
        summary = self._generate_summary(sequences)

        return {
            "format": self.FORMAT_NAME,
            "markdown": markdown,
            "json_content": json_content,
            "metadata": metadata,
            "summary": summary,
        }

    def _parse_with_biopython(self, file_path: str) -> List[Dict]:
        """ä½¿ç”¨ BioPython è§£æ FASTA æ–‡ä»¶å¹¶è¿›è¡Œæ·±åº¦ç”Ÿç‰©ä¿¡æ¯å­¦åˆ†æ"""
        sequences = []

        try:
            for record in self._SeqIO.parse(file_path, "fasta"):
                seq_data = {
                    "id": record.id,
                    "name": record.name,
                    "description": record.description,
                    "sequence": str(record.seq),
                    "length": len(record.seq),
                }

                # åˆ¤æ–­åºåˆ—ç±»å‹å¹¶è¿›è¡Œç›¸åº”åˆ†æ
                seq_type = self._detect_sequence_type(record.seq)
                seq_data["sequence_type"] = seq_type

                if seq_type == "nucleotide":
                    # æ ¸é…¸åºåˆ—åˆ†æ
                    seq_data.update(self._analyze_nucleotide(record.seq))
                elif seq_type == "protein":
                    # è›‹ç™½è´¨åºåˆ—åˆ†æ
                    seq_data.update(self._analyze_protein(record.seq))

                sequences.append(seq_data)

        except Exception as e:
            self.logger.error(f"Failed to parse FASTA file with BioPython: {e}")
            raise ValueError(f"FASTA parsing failed: {e}") from e

        return sequences

    def _detect_sequence_type(self, seq) -> str:
        """æ£€æµ‹åºåˆ—ç±»å‹ï¼ˆæ ¸é…¸ vs è›‹ç™½è´¨ï¼‰"""
        seq_str = str(seq).upper()
        nucleotide_chars = set("ATCGUN")

        # è®¡ç®—æ ¸é…¸å­—ç¬¦çš„æ¯”ä¾‹
        nucleotide_count = sum(1 for c in seq_str if c in nucleotide_chars)
        ratio = nucleotide_count / len(seq_str) if len(seq_str) > 0 else 0

        return "nucleotide" if ratio > 0.85 else "protein"

    def _analyze_nucleotide(self, seq) -> Dict:
        """æ·±åº¦åˆ†ææ ¸é…¸åºåˆ— - ä¸º RAG æä¾›ä¸°å¯Œçš„è¯­ä¹‰ä¿¡æ¯"""
        analysis = {}

        try:
            # 1. åŸºç¡€ç»Ÿè®¡
            analysis["gc_content"] = self._gc_fraction(seq)
            analysis["molecular_weight"] = self._molecular_weight(seq, seq_type="DNA")

            # 2. ç¢±åŸºç»„æˆ
            composition = self._analyze_composition(str(seq))
            analysis["composition"] = composition

            # 3. GC åæ–œåº¦ï¼ˆGC-skewï¼‰- ç”¨äºå¤åˆ¶èµ·ç‚¹é¢„æµ‹
            g_count = composition.get("G", 0)
            c_count = composition.get("C", 0)
            if (g_count + c_count) > 0:
                gc_skew = (g_count - c_count) / (g_count + c_count)
                analysis["gc_skew"] = gc_skew

            # 4. AT åæ–œåº¦ï¼ˆAT-skewï¼‰
            a_count = composition.get("A", 0)
            t_count = composition.get("T", 0)
            if (a_count + t_count) > 0:
                at_skew = (a_count - t_count) / (a_count + t_count)
                analysis["at_skew"] = at_skew

            # 5. å¯»æ‰¾å¼€æ”¾é˜…è¯»æ¡†ï¼ˆORFï¼‰
            orfs = self._find_orfs(seq)
            analysis["orfs"] = orfs
            analysis["longest_orf_length"] = max([orf["length"] for orf in orfs], default=0)

            # 6. ç¿»è¯‘æ‰€æœ‰6ä¸ªé˜…è¯»æ¡†ï¼ˆ3ä¸ªæ­£å‘ + 3ä¸ªåå‘ï¼‰
            translations = self._translate_six_frames(seq)
            analysis["translations"] = translations

            # 7. åºåˆ—å¤æ‚åº¦ï¼ˆç†µï¼‰
            analysis["sequence_entropy"] = self._calculate_entropy(str(seq))

            # 8. é‡å¤åºåˆ—æ£€æµ‹
            repeats = self._find_repeats(str(seq))
            analysis["repeats"] = repeats

            # 9. CpG å²›æ£€æµ‹ï¼ˆå¯¹äºçœŸæ ¸ç”Ÿç‰©é‡è¦ï¼‰
            cpg_islands = self._find_cpg_islands(str(seq))
            analysis["cpg_islands"] = cpg_islands

            # 10. è¯­ä¹‰æè¿°ï¼ˆç”¨äº RAGï¼‰
            analysis["semantic_description"] = self.semantic_gen.generate_nucleotide_semantics(analysis)

        except Exception as e:
            self.logger.warning(f"Some nucleotide analysis failed: {e}")

        return analysis

    def _analyze_protein(self, seq) -> Dict:
        """æ·±åº¦åˆ†æè›‹ç™½è´¨åºåˆ— - ä¸º RAG æä¾›ä¸°å¯Œçš„è¯­ä¹‰ä¿¡æ¯"""
        analysis = {}

        try:
            seq_str = str(seq)
            prot_analysis = self._ProteinAnalysis(seq_str)

            # 1. åŸºç¡€ç†åŒ–æ€§è´¨
            analysis["molecular_weight"] = prot_analysis.molecular_weight()
            analysis["aromaticity"] = prot_analysis.aromaticity()  # èŠ³é¦™æ€§
            analysis["instability_index"] = prot_analysis.instability_index()  # ä¸ç¨³å®šæŒ‡æ•°
            analysis["isoelectric_point"] = prot_analysis.isoelectric_point()  # ç­‰ç”µç‚¹

            # 2. æ°¨åŸºé…¸ç»„æˆ
            analysis["amino_acid_composition"] = prot_analysis.get_amino_acids_percent()

            # 3. äºŒçº§ç»“æ„é¢„æµ‹
            secondary_structure = prot_analysis.secondary_structure_fraction()
            analysis["secondary_structure"] = {
                "helix": secondary_structure[0],
                "turn": secondary_structure[1],
                "sheet": secondary_structure[2],
            }

            # 4. ç–æ°´æ€§åˆ†æ
            analysis["gravy"] = prot_analysis.gravy()  # Grand Average of Hydropathy

            # 5. æŸ”æ€§ï¼ˆflexibilityï¼‰
            flexibility = prot_analysis.flexibility()
            analysis["flexibility_mean"] = sum(flexibility) / len(flexibility) if flexibility else 0

            # 6. è›‹ç™½è´¨ç¨³å®šæ€§åˆ†ç±»
            if analysis["instability_index"] < 40:
                analysis["stability_class"] = "stable"
            else:
                analysis["stability_class"] = "unstable"

            # 7. åŠŸèƒ½åŸŸç‰¹å¾
            analysis["charge_at_ph7"] = self._calculate_charge_at_ph(seq_str, 7.0)

            # 8. æ°¨åŸºé…¸ç±»åˆ«ç»Ÿè®¡
            analysis["amino_acid_classes"] = self._classify_amino_acids(seq_str)

            # 9. æ½œåœ¨çš„ç¿»è¯‘åä¿®é¥°ä½ç‚¹
            analysis["ptm_sites"] = self._predict_ptm_sites(seq_str)

            # 10. è¯­ä¹‰æè¿°ï¼ˆç”¨äº RAGï¼‰
            analysis["semantic_description"] = self.semantic_gen.generate_protein_semantics(analysis)

        except Exception as e:
            self.logger.warning(f"Some protein analysis failed: {e}")

        return analysis

    def _find_orfs(self, seq, min_length: int = 100) -> List[Dict]:
        """å¯»æ‰¾å¼€æ”¾é˜…è¯»æ¡†ï¼ˆORFï¼‰"""
        orfs = []
        seq_str = str(seq)

        # å¯»æ‰¾èµ·å§‹å¯†ç å­ï¼ˆATGï¼‰åˆ°ç»ˆæ­¢å¯†ç å­ï¼ˆTAA, TAG, TGAï¼‰
        start_codons = ["ATG"]
        stop_codons = ["TAA", "TAG", "TGA"]

        for frame in range(3):
            i = frame
            while i < len(seq_str) - 2:
                codon = seq_str[i : i + 3]
                if codon in start_codons:
                    # æ‰¾åˆ°èµ·å§‹å¯†ç å­ï¼Œå¯»æ‰¾ç»ˆæ­¢å¯†ç å­
                    start = i
                    j = i + 3
                    while j < len(seq_str) - 2:
                        stop_codon = seq_str[j : j + 3]
                        if stop_codon in stop_codons:
                            length = j - start + 3
                            if length >= min_length:
                                orfs.append(
                                    {"start": start, "end": j + 3, "length": length, "frame": frame, "strand": "+"}
                                )
                            break
                        j += 3
                i += 3

        return orfs

    def _translate_six_frames(self, seq) -> Dict:
        """ç¿»è¯‘æ‰€æœ‰6ä¸ªé˜…è¯»æ¡†ï¼ˆæ™ºèƒ½æˆªæ–­ï¼‰"""
        translations = {}

        try:
            # æ­£å‘3ä¸ªé˜…è¯»æ¡†
            for frame in range(3):
                frame_seq = seq[frame:]
                translated = frame_seq.translate(to_stop=False)

                # æ™ºèƒ½æˆªæ–­ï¼šä¿ç•™åˆ°ç¬¬ä¸€ä¸ªç»ˆæ­¢å¯†ç å­æˆ–å‰200ä¸ªæ°¨åŸºé…¸
                translated_str = str(translated)
                stop_pos = translated_str.find("*")
                if stop_pos != -1:
                    # ä¿ç•™ç»ˆæ­¢å¯†ç å­åå°‘é‡æ°¨åŸºé…¸ä»¥æä¾›ä¸Šä¸‹æ–‡
                    translations[f"frame_{frame+1}_forward"] = translated_str[: stop_pos + 10]
                else:
                    translations[f"frame_{frame+1}_forward"] = translated_str[:200]

            # åå‘äº’è¡¥3ä¸ªé˜…è¯»æ¡†
            rev_comp = seq.reverse_complement()
            for frame in range(3):
                frame_seq = rev_comp[frame:]
                translated = frame_seq.translate(to_stop=False)

                translated_str = str(translated)
                stop_pos = translated_str.find("*")
                if stop_pos != -1:
                    translations[f"frame_{frame+1}_reverse"] = translated_str[: stop_pos + 10]
                else:
                    translations[f"frame_{frame+1}_reverse"] = translated_str[:200]
        except Exception:
            pass

        return translations

    def _calculate_entropy(self, seq: str) -> float:
        """è®¡ç®—åºåˆ—ç†µï¼ˆå¤æ‚åº¦æŒ‡æ ‡ï¼‰"""
        from math import log2

        if not seq:
            return 0.0

        # è®¡ç®—æ¯ä¸ªå­—ç¬¦çš„é¢‘ç‡
        freq = {}
        for char in seq:
            freq[char] = freq.get(char, 0) + 1

        # è®¡ç®—ç†µ
        entropy = 0.0
        for count in freq.values():
            p = count / len(seq)
            entropy -= p * log2(p)

        return entropy

    def _find_repeats(self, seq: str, min_length: int = 10) -> List[Dict]:
        """æ£€æµ‹é‡å¤åºåˆ—ï¼ˆä¼˜åŒ–ç®—æ³• - ä½¿ç”¨æ»‘åŠ¨çª—å£å’Œå­—å…¸ï¼‰"""
        repeats = []
        seq_len = len(seq)
        max_repeats = 15  # æœ€å¤šè¿”å›15ä¸ªé‡å¤

        # ä½¿ç”¨å­—å…¸è®°å½•å·²è®¿é—®çš„æ¨¡å¼,é¿å…é‡å¤æ£€æµ‹
        seen_patterns = set()

        # ä»è¾ƒé•¿çš„æ¨¡å¼å¼€å§‹æ£€æµ‹ï¼ˆæ›´æœ‰æ„ä¹‰ï¼‰
        for length in range(min(50, seq_len // 3), max(min_length - 1, 2), -1):
            if len(repeats) >= max_repeats:
                break

            # ä½¿ç”¨æ»‘åŠ¨çª—å£
            for i in range(seq_len - length * 2 + 1):
                if len(repeats) >= max_repeats:
                    break

                pattern = seq[i : i + length]

                # è·³è¿‡å·²æ£€æµ‹çš„æ¨¡å¼
                if pattern in seen_patterns:
                    continue

                # æ£€æŸ¥æ˜¯å¦ä¸ºä¸²è”é‡å¤
                if seq[i + length : i + length * 2] == pattern:
                    seen_patterns.add(pattern)

                    # è®¡ç®—é‡å¤æ¬¡æ•°
                    repeat_count = 2
                    pos = i + length * 2
                    while pos + length <= seq_len and seq[pos : pos + length] == pattern:
                        repeat_count += 1
                        pos += length

                    repeats.append(
                        {
                            "position": i,
                            "length": length,
                            "repeat_count": repeat_count,
                            "pattern": pattern[:30] + "..." if len(pattern) > 30 else pattern,
                        }
                    )

        # æŒ‰é‡å¤å•å…ƒé•¿åº¦æ’åºï¼ˆé•¿çš„æ›´é‡è¦ï¼‰
        repeats.sort(key=lambda x: x["length"] * x["repeat_count"], reverse=True)

        return repeats[:max_repeats]

    def _find_cpg_islands(self, seq: str) -> List[Dict]:
        """æ£€æµ‹ CpG å²›ï¼ˆCG å¯Œé›†åŒºåŸŸï¼‰"""
        islands = []
        window_size = 200
        threshold = 0.6  # GC å«é‡é˜ˆå€¼

        for i in range(0, len(seq) - window_size, 50):
            window = seq[i : i + window_size]
            gc_count = window.count("G") + window.count("C")
            gc_ratio = gc_count / window_size

            if gc_ratio >= threshold:
                # æ£€æµ‹ CpG æ•°é‡
                cpg_count = window.count("CG")
                expected_cpg = (window.count("C") * window.count("G")) / window_size

                if cpg_count > 0 and expected_cpg > 0:
                    obs_exp_ratio = cpg_count / expected_cpg

                    if obs_exp_ratio >= 0.6:
                        islands.append(
                            {"start": i, "end": i + window_size, "gc_content": gc_ratio, "cpg_ratio": obs_exp_ratio}
                        )

        return islands

    def _classify_amino_acids(self, seq: str) -> Dict:
        """æ°¨åŸºé…¸åˆ†ç±»ç»Ÿè®¡"""
        hydrophobic = set("AVILMFWP")
        polar = set("STNQ")
        charged_positive = set("KRH")
        charged_negative = set("DE")
        aromatic = set("FWY")

        classes = {"hydrophobic": 0, "polar": 0, "charged_positive": 0, "charged_negative": 0, "aromatic": 0}

        for aa in seq.upper():
            if aa in hydrophobic:
                classes["hydrophobic"] += 1
            elif aa in polar:
                classes["polar"] += 1
            elif aa in charged_positive:
                classes["charged_positive"] += 1
            elif aa in charged_negative:
                classes["charged_negative"] += 1
            if aa in aromatic:
                classes["aromatic"] += 1

        # è½¬æ¢ä¸ºç™¾åˆ†æ¯”
        total = len(seq)
        return {k: v / total if total > 0 else 0 for k, v in classes.items()}

    def _calculate_charge_at_ph(self, seq: str, ph: float) -> float:
        """è®¡ç®—æŒ‡å®š pH ä¸‹çš„å‡€ç”µè·"""
        # ç®€åŒ–è®¡ç®—
        k_count = seq.count("K")
        r_count = seq.count("R")
        h_count = seq.count("H")
        d_count = seq.count("D")
        e_count = seq.count("E")

        # ç®€åŒ–çš„ç”µè·è®¡ç®—ï¼ˆå®é™…æ›´å¤æ‚ï¼‰
        positive_charge = k_count + r_count + (h_count * 0.5 if ph < 7 else 0)
        negative_charge = d_count + e_count

        return positive_charge - negative_charge

    def _predict_ptm_sites(self, seq: str) -> Dict:
        """é¢„æµ‹ç¿»è¯‘åä¿®é¥°ä½ç‚¹ï¼ˆæ”¹è¿›ç‰ˆ - è€ƒè™‘ä¸Šä¸‹æ–‡ï¼‰"""
        ptm_sites = {
            "phosphorylation": [],  # ç£·é…¸åŒ–ä½ç‚¹ (S, T, Y)
            "glycosylation": [],  # N-ç³–åŸºåŒ–ä½ç‚¹ (N-X-S/T æ¨¡å¼)
            "acetylation": [],  # ä¹™é…°åŒ–ä½ç‚¹ (K)
        }

        seq_len = len(seq)

        for i, aa in enumerate(seq):
            # ç£·é…¸åŒ–ä½ç‚¹ï¼šS, T, Yï¼ˆè€ƒè™‘å‘¨å›´åºåˆ—ï¼‰
            if aa in "STY":
                # æå–ä¸Šä¸‹æ–‡ï¼ˆå‰åå„2ä¸ªæ°¨åŸºé…¸ï¼‰
                context_start = max(0, i - 2)
                context_end = min(seq_len, i + 3)
                context = seq[context_start:context_end]

                # ç®€å•æ‰“åˆ†ï¼šPro åœ¨ +1 ä½ç½®å¢åŠ å¯èƒ½æ€§
                score = 1.0
                if i + 1 < seq_len and seq[i + 1] == "P":
                    score = 2.0  # S/T-P æ˜¯ç»å…¸ç£·é…¸åŒ–æ¨¡å¼

                ptm_sites["phosphorylation"].append(
                    {"position": i + 1, "residue": aa, "context": context, "score": score}
                )

            # N-ç³–åŸºåŒ–ä½ç‚¹ï¼šN-X-S/T æ¨¡å¼ï¼ˆX ä¸æ˜¯ Pï¼‰
            if aa == "N" and i + 2 < seq_len:
                x = seq[i + 1]
                st = seq[i + 2]
                if x != "P" and st in "ST":
                    ptm_sites["glycosylation"].append({"position": i + 1, "motif": seq[i : i + 3], "type": "N-linked"})

            # ä¹™é…°åŒ–ä½ç‚¹ï¼šKï¼ˆè€ƒè™‘å‘¨å›´åºåˆ—ï¼‰
            if aa == "K":
                context_start = max(0, i - 2)
                context_end = min(seq_len, i + 3)
                context = seq[context_start:context_end]

                ptm_sites["acetylation"].append({"position": i + 1, "context": context})

        # åªä¿ç•™å‰15ä¸ªä½ç‚¹ï¼ˆæ›´å¤šä¿¡æ¯ï¼‰
        for key in ptm_sites:
            ptm_sites[key] = ptm_sites[key][:15]

        return ptm_sites

    def _generate_markdown(self, sequences: List[Dict], max_preview: int) -> str:
        """ç”Ÿæˆ Markdown æ ¼å¼"""
        title = self.common_i18n.get("fasta_title")
        lines = [f"# {title}\n"]

        # æ€»ä½“ç»Ÿè®¡
        total_seqs = len(sequences)
        total_length = sum(seq["length"] for seq in sequences)
        avg_length = total_length / total_seqs if total_seqs > 0 else 0

        lines.append(f"## ğŸ“Š {self.common_i18n.get('statistics')}\n")
        lines.append(f"- **{self.common_i18n.get('sequence_count')}**: {total_seqs}")
        lines.append(f"- **{self.common_i18n.get('total_length')}**: {total_length:,} bp")
        lines.append(f"- **{self.common_i18n.get('average_length')}**: {avg_length:.0f} bp")
        lines.append(
            f"- **{self.common_i18n.get('shortest_sequence')}**: {min((s['length'] for s in sequences), default=0):,} bp"
        )
        lines.append(
            f"- **{self.common_i18n.get('longest_sequence')}**: {max((s['length'] for s in sequences), default=0):,} bp\n"
        )

        # åºåˆ—è¯¦æƒ…
        lines.append(f"## ğŸ§¬ {self.common_i18n.get('sequence_details')}\n")

        for i, seq in enumerate(sequences, 1):
            lines.append(f"### {i}. {seq['id']}\n")
            lines.append(f"**Description**: {seq['description']}\n")
            lines.append(f"**Length**: {seq['length']:,} bp\n")

            # åºåˆ—é¢„è§ˆ
            preview = seq["sequence"][:max_preview]
            if len(seq["sequence"]) > max_preview:
                preview += "..."

            lines.append(f"**{self.common_i18n.get('sequence_preview')}**:\n```\n{preview}\n```\n")

            # è¯­ä¹‰æè¿°ï¼ˆæ ¸å¿ƒ RAG ä¿¡æ¯ï¼‰
            if seq.get("semantic_description"):
                lines.append(
                    f"**ğŸ”¬ {self.common_i18n.get('biological_significance')}**:\n{seq['semantic_description']}\n"
                )

            # æ ¹æ®åºåˆ—ç±»å‹æ˜¾ç¤ºä¸åŒçš„åˆ†æç»“æœ
            if seq.get("sequence_type") == "nucleotide":
                # æ ¸é…¸åºåˆ—åˆ†æ
                if seq.get("gc_content") is not None:
                    gc_percent = seq["gc_content"] * 100
                    lines.append(f"**{self.common_i18n.get('gc_content')}**: {gc_percent:.2f}%")

                if seq.get("longest_orf_length", 0) > 0:
                    lines.append(f"**{self.common_i18n.get('longest_orf')}**: {seq['longest_orf_length']} bp")

                if seq.get("cpg_islands"):
                    lines.append(f"**{self.common_i18n.get('cpg_islands')}**: {len(seq['cpg_islands'])}")

                if seq.get("sequence_entropy"):
                    lines.append(f"**{self.common_i18n.get('sequence_complexity')}**: {seq['sequence_entropy']:.2f}")

                lines.append("")

            elif seq.get("sequence_type") == "protein":
                # è›‹ç™½è´¨åºåˆ—åˆ†æ
                if seq.get("molecular_weight"):
                    mw = seq["molecular_weight"] / 1000
                    lines.append(f"**{self.common_i18n.get('molecular_weight')}**: {mw:.1f} kDa")

                if seq.get("isoelectric_point"):
                    lines.append(f"**{self.common_i18n.get('isoelectric_point')}**: {seq['isoelectric_point']:.2f}")

                if seq.get("stability_class"):
                    lines.append(f"**{self.common_i18n.get('stability')}**: {seq['stability_class']}")

                if seq.get("gravy") is not None:
                    lines.append(f"**{self.common_i18n.get('hydropathy')}**: {seq['gravy']:.2f}")

                # äºŒçº§ç»“æ„
                ss = seq.get("secondary_structure", {})
                if ss:
                    lines.append(
                        f"**{self.common_i18n.get('secondary_structure')}**: Î±-helix {ss.get('helix', 0)*100:.1f}%, Î²-sheet {ss.get('sheet', 0)*100:.1f}%"
                    )

                lines.append("")

        return "\n".join(lines)

    def _generate_json(self, sequences: List[Dict], include_full: bool) -> Dict:
        """ç”Ÿæˆ JSON æ ¼å¼ - åŒ…å«å®Œæ•´çš„ç”Ÿç‰©ä¿¡æ¯å­¦åˆ†æ"""
        json_sequences = []

        for seq in sequences:
            json_seq = {
                "id": seq["id"],
                "name": seq.get("name", seq["id"]),
                "description": seq["description"],
                "length": seq["length"],
                "sequence_type": seq.get("sequence_type", "unknown"),
            }

            # è¯­ä¹‰æè¿°ï¼ˆRAG æ ¸å¿ƒï¼‰
            if seq.get("semantic_description"):
                json_seq["semantic_description"] = seq["semantic_description"]

            # æ ¹æ®åºåˆ—ç±»å‹åŒ…å«ä¸åŒçš„åˆ†æç»“æœ
            if seq.get("sequence_type") == "nucleotide":
                # æ ¸é…¸åºåˆ—åˆ†ææ•°æ®
                json_seq["analysis"] = {
                    "gc_content": seq.get("gc_content"),
                    "gc_skew": seq.get("gc_skew"),
                    "at_skew": seq.get("at_skew"),
                    "molecular_weight": seq.get("molecular_weight"),
                    "sequence_entropy": seq.get("sequence_entropy"),
                    "longest_orf_length": seq.get("longest_orf_length", 0),
                    "orf_count": len(seq.get("orfs", [])),
                    "cpg_island_count": len(seq.get("cpg_islands", [])),
                    "repeat_count": len(seq.get("repeats", [])),
                }

                # ORF è¯¦æƒ…ï¼ˆå‰5ä¸ªï¼‰
                if seq.get("orfs"):
                    json_seq["top_orfs"] = seq["orfs"][:5]

                # CpG å²›è¯¦æƒ…
                if seq.get("cpg_islands"):
                    json_seq["cpg_islands"] = seq["cpg_islands"]

            elif seq.get("sequence_type") == "protein":
                # è›‹ç™½è´¨åºåˆ—åˆ†ææ•°æ®
                json_seq["analysis"] = {
                    "molecular_weight": seq.get("molecular_weight"),
                    "isoelectric_point": seq.get("isoelectric_point"),
                    "aromaticity": seq.get("aromaticity"),
                    "instability_index": seq.get("instability_index"),
                    "stability_class": seq.get("stability_class"),
                    "gravy": seq.get("gravy"),
                    "charge_at_ph7": seq.get("charge_at_ph7"),
                }

                # äºŒçº§ç»“æ„
                if seq.get("secondary_structure"):
                    json_seq["secondary_structure"] = seq["secondary_structure"]

                # æ°¨åŸºé…¸åˆ†ç±»
                if seq.get("amino_acid_classes"):
                    json_seq["amino_acid_classes"] = seq["amino_acid_classes"]

                # PTM ä½ç‚¹ï¼ˆå‰10ä¸ªï¼‰
                if seq.get("ptm_sites"):
                    json_seq["ptm_sites_summary"] = {
                        "phosphorylation_count": len(seq["ptm_sites"].get("phosphorylation", [])),
                        "glycosylation_count": len(seq["ptm_sites"].get("glycosylation", [])),
                        "acetylation_count": len(seq["ptm_sites"].get("acetylation", [])),
                    }

            # å¯é€‰ï¼šåŒ…å«å®Œæ•´åºåˆ—
            if include_full:
                json_seq["sequence"] = seq["sequence"]

            json_sequences.append(json_seq)

        return {
            "sequences": json_sequences,
            "total_count": len(sequences),
            "total_length": sum(s["length"] for s in sequences),
            "analysis_version": "1.0",
            "bioinformatics_features": [
                "sequence_type_detection",
                "gc_content_analysis",
                "orf_prediction",
                "cpg_island_detection",
                "protein_properties",
                "secondary_structure",
                "ptm_site_prediction",
                "semantic_description",
            ],
        }

    def _generate_metadata(self, sequences: List[Dict]) -> Dict:
        """ç”Ÿæˆå…ƒæ•°æ®"""
        return {
            "format": "FASTA",
            "sequence_count": len(sequences),
            "total_bases": sum(s["length"] for s in sequences),
            "file_type": "biological_sequence",
        }

    def _generate_summary(self, sequences: List[Dict]) -> str:
        """ç”Ÿæˆæ‘˜è¦"""
        count = len(sequences)
        total_length = sum(s["length"] for s in sequences)

        if count == 0:
            return self.common_i18n.get("empty_file")

        return self.common_i18n.get("sequence_summary", count=count, length=total_length)

    def _analyze_composition(self, sequence: str) -> Dict[str, int]:
        """åˆ†æç¢±åŸº/æ°¨åŸºé…¸ç»„æˆ"""
        composition = {}
        for char in sequence.upper():
            composition[char] = composition.get(char, 0) + 1
        return composition

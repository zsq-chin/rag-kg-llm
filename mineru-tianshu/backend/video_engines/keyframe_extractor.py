"""
å…³é”®å¸§æå–å¼•æ“
åœºæ™¯æ£€æµ‹ â†’ è´¨é‡è¿‡æ»¤ â†’ å›¾åƒå»é‡ â†’ OCR
"""

import cv2
import numpy as np
from pathlib import Path
from typing import List, Dict, Any, Tuple
from loguru import logger
import imagehash
from PIL import Image
import shutil


class KeyFrame:
    """å…³é”®å¸§æ•°æ®ç»“æ„"""

    def __init__(self, timestamp: float, frame_number: int, image_path: str):
        self.timestamp = timestamp
        self.frame_number = frame_number
        self.image_path = image_path
        self.quality_score = 0.0
        self.phash = None
        self.ocr_result = None


class KeyframeExtractor:
    """å…³é”®å¸§æå–å™¨"""

    def __init__(
        self,
        scene_threshold: float = 30.0,
        min_scene_length: float = 1.0,
        quality_threshold: float = 100.0,
        phash_threshold: int = 5,
        brightness_range: Tuple[int, int] = (30, 225),
    ):
        self.scene_threshold = scene_threshold
        self.min_scene_length = min_scene_length
        self.quality_threshold = quality_threshold
        self.phash_threshold = phash_threshold
        self.brightness_range = brightness_range

    def extract(self, video_path: str, output_dir: str) -> List[KeyFrame]:
        """
        æå–å…³é”®å¸§ä¸»æµç¨‹
        """
        video_path = Path(video_path)
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)

        logger.info(f"ğŸ¬ å¼€å§‹æå–å…³é”®å¸§: {video_path.name}")

        # Stage 1: åœºæ™¯æ£€æµ‹
        logger.info("ğŸ“ Stage 1: åœºæ™¯æ£€æµ‹...")
        scene_frames = self._detect_scenes(str(video_path))
        logger.info(f"   æ£€æµ‹åˆ° {len(scene_frames)} ä¸ªåœºæ™¯å˜åŒ–ç‚¹")

        # Stage 2: æå–å…³é”®å¸§å›¾åƒ
        logger.info("ğŸ–¼ï¸  Stage 2: æå–å…³é”®å¸§...")
        keyframes = self._extract_frames(str(video_path), scene_frames, output_dir)
        logger.info(f"   æå–äº† {len(keyframes)} å¸§")

        # Stage 3: å›¾åƒè´¨é‡è¿‡æ»¤
        logger.info("âœ¨ Stage 3: è´¨é‡è¿‡æ»¤...")
        quality_frames = self._filter_quality(keyframes)
        logger.info(f"   ä¿ç•™ {len(quality_frames)} ä¸ªé«˜è´¨é‡å¸§")

        # Stage 4: å›¾åƒå»é‡
        logger.info("ğŸ”„ Stage 4: å›¾åƒå»é‡...")
        unique_frames = self._deduplicate_images(quality_frames)
        logger.info(f"   å»é‡åå‰©ä½™ {len(unique_frames)} å¸§")

        logger.info(f"âœ… å…³é”®å¸§æå–å®Œæˆ: {len(unique_frames)} å¸§")
        return unique_frames

    def _detect_scenes(self, video_path: str) -> List[Tuple[float, int]]:
        """
        åœºæ™¯æ£€æµ‹ï¼šåŸºäºå¸§å·®å¼‚æ£€æµ‹åœºæ™¯å˜åŒ–
        è¿”å›: [(timestamp, frame_number), ...]
        """
        cap = cv2.VideoCapture(video_path)
        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

        scene_frames = []
        prev_frame = None
        frame_count = 0
        last_scene_frame = 0

        min_frames = int(self.min_scene_length * fps)

        while True:
            ret, frame = cap.read()
            if not ret:
                break

            # è½¬æ¢ä¸ºç°åº¦å¹¶ç¼©å°ä»¥åŠ å¿«è®¡ç®—
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            small = cv2.resize(gray, (160, 90))

            if prev_frame is not None:
                # è®¡ç®—å¸§å·®å¼‚
                diff = cv2.absdiff(small, prev_frame)
                diff_score = np.mean(diff)

                # æ£€æµ‹åœºæ™¯å˜åŒ–
                if diff_score > self.scene_threshold:
                    # ç¡®ä¿æœ€å°åœºæ™¯é•¿åº¦
                    if frame_count - last_scene_frame >= min_frames:
                        timestamp = frame_count / fps
                        scene_frames.append((timestamp, frame_count))
                        last_scene_frame = frame_count

            prev_frame = small
            frame_count += 1

            # æ¯å¤„ç† 1000 å¸§è¾“å‡ºä¸€æ¬¡è¿›åº¦
            if frame_count % 1000 == 0:
                progress = (frame_count / total_frames) * 100
                logger.debug(f"   åœºæ™¯æ£€æµ‹è¿›åº¦: {progress:.1f}%")

        cap.release()

        # å¦‚æœæ²¡æ£€æµ‹åˆ°åœºæ™¯å˜åŒ–ï¼Œä½¿ç”¨å›ºå®šé—´éš”
        if len(scene_frames) == 0:
            logger.warning("   æœªæ£€æµ‹åˆ°åœºæ™¯å˜åŒ–ï¼Œä½¿ç”¨å›ºå®šé—´éš”é‡‡æ ·")
            interval = 10  # æ¯ 10 ç§’
            for i in range(0, int(total_frames / fps), interval):
                scene_frames.append((float(i), int(i * fps)))

        return scene_frames

    def _extract_frames(
        self, video_path: str, scene_frames: List[Tuple[float, int]], output_dir: Path
    ) -> List[KeyFrame]:
        """æå–æŒ‡å®šå¸§çš„å›¾åƒ"""
        cap = cv2.VideoCapture(video_path)
        keyframes = []

        for idx, (timestamp, frame_number) in enumerate(scene_frames):
            # å®šä½åˆ°æŒ‡å®šå¸§
            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)
            ret, frame = cap.read()

            if not ret:
                continue

            # ä¿å­˜å›¾åƒ
            image_path = output_dir / f"frame_{idx:04d}_{frame_number:06d}.jpg"
            cv2.imwrite(str(image_path), frame, [cv2.IMWRITE_JPEG_QUALITY, 95])

            keyframe = KeyFrame(timestamp, frame_number, str(image_path))
            keyframes.append(keyframe)

        cap.release()
        return keyframes

    def _filter_quality(self, keyframes: List[KeyFrame]) -> List[KeyFrame]:
        """å›¾åƒè´¨é‡è¿‡æ»¤"""
        quality_frames = []

        for kf in keyframes:
            # è¯»å–å›¾åƒ
            img = cv2.imread(kf.image_path)
            if img is None:
                continue

            # è¯„ä¼°æ¸…æ™°åº¦ï¼ˆæ‹‰æ™®æ‹‰æ–¯æ–¹å·®ï¼‰
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            sharpness = cv2.Laplacian(gray, cv2.CV_64F).var()

            # è¯„ä¼°äº®åº¦
            brightness = np.mean(gray)

            # è´¨é‡è¯„åˆ†
            is_sharp = sharpness >= self.quality_threshold
            is_bright = self.brightness_range[0] <= brightness <= self.brightness_range[1]

            if is_sharp and is_bright:
                kf.quality_score = sharpness
                quality_frames.append(kf)
            else:
                # åˆ é™¤ä½è´¨é‡å›¾åƒ
                try:
                    Path(kf.image_path).unlink()
                except Exception:
                    pass

        return quality_frames

    def _deduplicate_images(self, keyframes: List[KeyFrame]) -> List[KeyFrame]:
        """ä½¿ç”¨æ„ŸçŸ¥å“ˆå¸Œå»é‡"""
        if len(keyframes) == 0:
            return []

        unique_frames = []
        prev_hash = None

        for kf in keyframes:
            try:
                # è®¡ç®— pHash
                img = Image.open(kf.image_path)
                curr_hash = imagehash.phash(img)
                kf.phash = curr_hash

                # ä¸å‰ä¸€å¸§å¯¹æ¯”
                if prev_hash is None:
                    # ç¬¬ä¸€å¸§ï¼Œä¿ç•™
                    unique_frames.append(kf)
                    prev_hash = curr_hash
                else:
                    # è®¡ç®—æ±‰æ˜è·ç¦»
                    hamming_dist = curr_hash - prev_hash

                    if hamming_dist > self.phash_threshold:
                        # å·®å¼‚å¤§ï¼Œä¿ç•™
                        unique_frames.append(kf)
                        prev_hash = curr_hash
                    else:
                        # ç›¸ä¼¼ï¼Œåˆ é™¤
                        try:
                            Path(kf.image_path).unlink()
                        except Exception:
                            pass
            except Exception as e:
                logger.debug(f"å¤„ç†å¸§ {kf.image_path} æ—¶å‡ºé”™: {e}")
                continue

        return unique_frames

    def cleanup(self, keyframes: List[KeyFrame]):
        """æ¸…ç†ä¸´æ—¶å›¾åƒæ–‡ä»¶"""
        for kf in keyframes:
            try:
                if Path(kf.image_path).exists():
                    Path(kf.image_path).unlink()
            except Exception:
                pass


class VideoOCREngine:
    """è§†é¢‘ OCR å¼•æ“ï¼šå…³é”®å¸§æå– + OCR è¯†åˆ«"""

    def __init__(self, ocr_backend: str = "paddleocr-vl", keep_keyframes: bool = False):
        self.ocr_backend = ocr_backend
        self.keep_keyframes = keep_keyframes
        self.keyframe_extractor = KeyframeExtractor()
        self._ocr_engine = None

    def _load_ocr_engine(self):
        """åŠ è½½ OCR å¼•æ“"""
        if self._ocr_engine is not None:
            return self._ocr_engine

        if self.ocr_backend == "paddleocr-vl":
            from paddleocr_vl import PaddleOCRVLEngine

            self._ocr_engine = PaddleOCRVLEngine()
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„ OCR å¼•æ“: {self.ocr_backend}")

        return self._ocr_engine

    def process(self, video_path: str, output_path: str) -> Dict[str, Any]:
        """
        å¤„ç†è§†é¢‘ï¼šæå–å…³é”®å¸§å¹¶è¿›è¡Œ OCR
        """
        video_path = Path(video_path)
        output_path = Path(output_path)
        output_path.mkdir(parents=True, exist_ok=True)

        # åˆ›å»ºä¸´æ—¶ç›®å½•å­˜æ”¾å…³é”®å¸§
        temp_dir = output_path / "keyframes_temp"
        temp_dir.mkdir(exist_ok=True)

        try:
            # Stage 1-4: æå–å…³é”®å¸§
            keyframes = self.keyframe_extractor.extract(str(video_path), str(temp_dir))

            if len(keyframes) == 0:
                logger.warning("æœªæå–åˆ°ä»»ä½•å…³é”®å¸§")
                return {"success": False, "message": "æœªæå–åˆ°å…³é”®å¸§", "keyframes": []}

            # Stage 5: OCR å¤„ç†
            logger.info(f"ğŸ“ Stage 5: OCR è¯†åˆ« ({len(keyframes)} å¸§)...")
            ocr_engine = self._load_ocr_engine()

            results = []
            for idx, kf in enumerate(keyframes):
                logger.info(f"   å¤„ç† {idx+1}/{len(keyframes)}: {Path(kf.image_path).name}")

                try:
                    # è°ƒç”¨ OCR å¼•æ“
                    ocr_result = ocr_engine.parse(file_path=kf.image_path, output_path=str(temp_dir))

                    # æå–æ–‡å­—å†…å®¹
                    ocr_text = ""
                    if ocr_result.get("markdown"):
                        ocr_text = ocr_result["markdown"]
                    elif ocr_result.get("json_data"):
                        # ä» JSON æå–æ–‡å­—
                        json_data = ocr_result["json_data"]
                        if "content" in json_data and "text" in json_data["content"]:
                            ocr_text = json_data["content"]["text"]

                    kf.ocr_result = ocr_text

                    results.append(
                        {
                            "timestamp": kf.timestamp,
                            "frame_number": kf.frame_number,
                            "image_path": kf.image_path,
                            "ocr_text": ocr_text,
                        }
                    )

                except Exception as e:
                    logger.warning(f"   OCR å¤±è´¥: {e}")
                    results.append(
                        {
                            "timestamp": kf.timestamp,
                            "frame_number": kf.frame_number,
                            "image_path": kf.image_path,
                            "ocr_text": "",
                            "error": str(e),
                        }
                    )

            # Stage 6: æ–‡æœ¬å»é‡
            logger.info("ğŸ”„ Stage 6: æ–‡æœ¬å»é‡...")
            unique_results = self._deduplicate_text(results)
            logger.info(f"   å»é‡åå‰©ä½™ {len(unique_results)} ä¸ªç»“æœ")

            # ç”Ÿæˆè¾“å‡º
            markdown_content = self._generate_markdown(unique_results, video_path.name)
            markdown_file = output_path / f"{video_path.stem}_keyframes.md"
            markdown_file.write_text(markdown_content, encoding="utf-8")

            # ä¿å­˜ JSON
            import json

            json_file = output_path / f"{video_path.stem}_keyframes.json"
            with open(json_file, "w", encoding="utf-8") as f:
                json.dump(
                    {"video": video_path.name, "total_keyframes": len(unique_results), "keyframes": unique_results},
                    f,
                    ensure_ascii=False,
                    indent=2,
                )

            logger.info("âœ… è§†é¢‘ OCR å®Œæˆ")
            logger.info(f"   Markdown: {markdown_file}")
            logger.info(f"   JSON: {json_file}")

            return {
                "success": True,
                "output_path": str(output_path),
                "markdown_file": str(markdown_file),
                "json_file": str(json_file),
                "markdown": markdown_content,
                "keyframes": unique_results,
                "total_keyframes": len(unique_results),
            }

        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if not self.keep_keyframes:
                try:
                    shutil.rmtree(temp_dir)
                except Exception:
                    pass

    def _deduplicate_text(self, results: List[Dict]) -> List[Dict]:
        """æ–‡æœ¬å»é‡ï¼šä½¿ç”¨ç¼–è¾‘è·ç¦»"""
        if len(results) <= 1:
            return results

        from difflib import SequenceMatcher

        unique_results = [results[0]]

        for result in results[1:]:
            current_text = result["ocr_text"].strip()
            if not current_text:
                continue

            # ä¸æœ€åä¸€ä¸ªç»“æœå¯¹æ¯”
            last_text = unique_results[-1]["ocr_text"].strip()

            if not last_text:
                unique_results.append(result)
                continue

            # è®¡ç®—ç›¸ä¼¼åº¦
            similarity = SequenceMatcher(None, current_text, last_text).ratio()

            if similarity < 0.9:  # ç›¸ä¼¼åº¦ä½äº 90%ï¼Œè®¤ä¸ºä¸åŒ
                unique_results.append(result)

        return unique_results

    def _generate_markdown(self, results: List[Dict], video_name: str) -> str:
        """ç”Ÿæˆ Markdown è¾“å‡º"""
        lines = []
        lines.append(f"# è§†é¢‘å…³é”®å¸§ OCR ç»“æœ: {video_name}\n")
        lines.append(f"**æ€»å¸§æ•°**: {len(results)}\n")
        lines.append("---\n")

        for idx, result in enumerate(results, 1):
            timestamp = result["timestamp"]
            minutes = int(timestamp // 60)
            seconds = int(timestamp % 60)

            lines.append(f"## å…³é”®å¸§ {idx} - [{minutes:02d}:{seconds:02d}]\n")
            lines.append(f"**æ—¶é—´æˆ³**: {timestamp:.2f}s\n")

            ocr_text = result.get("ocr_text", "").strip()
            if ocr_text:
                lines.append(f"**å†…å®¹**:\n\n{ocr_text}\n")
            else:
                lines.append("_æœªæ£€æµ‹åˆ°æ–‡å­—å†…å®¹_\n")

            lines.append("---\n")

        return "\n".join(lines)

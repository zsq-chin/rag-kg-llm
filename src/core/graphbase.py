import csv
import os
import json
import warnings
import chardet
import sys
import traceback
import shutil
from pathlib import Path
from typing import List
import requests

import torch
from neo4j import GraphDatabase as GD

from src import config
from src.utils import logger

warnings.filterwarnings("ignore", category=UserWarning)


UIE_MODEL = None

class GraphDatabase:
    def __init__(self):
        self.driver = None
        self.files = []
        self.status = "closed"
        self.kgdb_name = "neo4j"
        self.embed_model_name = None
        self.work_dir = os.path.join(config.save_dir, "knowledge_graph", self.kgdb_name)
        os.makedirs(self.work_dir, exist_ok=True)

        # å°è¯•åŠ è½½å·²ä¿å­˜çš„å›¾æ•°æ®åº“ä¿¡æ¯
        if not self.load_graph_info():
            logger.debug("åˆ›å»ºæ–°çš„å›¾æ•°æ®åº“é…ç½®")

        self.start()

    def start(self):
        if not config.enable_knowledge_graph or not config.enable_knowledge_base:
            return

        uri = os.environ.get("NEO4J_URI", "bolt://localhost:7687")
        username = os.environ.get("NEO4J_USERNAME", "neo4j")
        password = os.environ.get("NEO4J_PASSWORD", "0123456789")
        logger.info(f"Connecting to Neo4j: {uri}/{self.kgdb_name}")
        try:
            self.driver = GD.driver(f"{uri}/{self.kgdb_name}", auth=(username, password))
            self.status = "open"
            logger.info(f"Connected to Neo4j: {self.get_graph_info(self.kgdb_name)}")
            # è¿æ¥æˆåŠŸåä¿å­˜å›¾æ•°æ®åº“ä¿¡æ¯
            self.save_graph_info(self.kgdb_name)
        except Exception as e:
            logger.error(f"Failed to connect to Neo4j: {e}, {uri}, {self.kgdb_name}, {username}, {password}")
            self.config.enable_knowledge_graph = False

    def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        self.driver.close()

    def is_running(self):
        """æ£€æŸ¥å›¾æ•°æ®åº“æ˜¯å¦æ­£åœ¨è¿è¡Œ"""
        if not config.enable_knowledge_graph or not config.enable_knowledge_base:
            return False
        else:
            return self.status == "open"

    def get_sample_nodes(self, kgdb_name='neo4j', num=50):
        """è·å–æŒ‡å®šæ•°æ®åº“çš„ num ä¸ªèŠ‚ç‚¹ä¿¡æ¯"""
        self.use_database(kgdb_name)
        def query(tx, num):
            result = tx.run("MATCH (n)-[r]->(m) RETURN n, r, m LIMIT $num", num=int(num))
            return result.values()

        with self.driver.session() as session:
            return session.execute_read(query, num)

    def create_graph_database(self, kgdb_name):
        """åˆ›å»ºæ–°çš„æ•°æ®åº“ï¼Œå¦‚æœå·²å­˜åœ¨åˆ™è¿”å›å·²æœ‰æ•°æ®åº“çš„åç§°"""
        with self.driver.session() as session:
            existing_databases = session.run("SHOW DATABASES")
            existing_db_names = [db['name'] for db in existing_databases]

            if existing_db_names:
                print(f"å·²å­˜åœ¨æ•°æ®åº“: {existing_db_names[0]}")
                return existing_db_names[0]  # è¿”å›æ‰€æœ‰å·²æœ‰æ•°æ®åº“åç§°

            session.run(f"CREATE DATABASE {kgdb_name}")
            print(f"æ•°æ®åº“ '{kgdb_name}' åˆ›å»ºæˆåŠŸ.")
            return kgdb_name  # è¿”å›åˆ›å»ºçš„æ•°æ®åº“åç§°

    def use_database(self, kgdb_name="neo4j"):
        """åˆ‡æ¢åˆ°æŒ‡å®šæ•°æ®åº“"""
        assert kgdb_name == self.kgdb_name, f"ä¼ å…¥çš„æ•°æ®åº“åç§° '{kgdb_name}' ä¸å½“å‰å®ä¾‹çš„æ•°æ®åº“åç§° '{self.kgdb_name}' ä¸ä¸€è‡´"
        if self.status == "closed":
            self.start()

    def txt_add_entity(self, triples, kgdb_name='neo4j'):
        """æ·»åŠ å®ä½“ä¸‰å…ƒç»„"""
        self.use_database(kgdb_name)
        def create(tx, triples):
            for triple in triples:
                h = triple['h']
                t = triple['t']
                r = triple['r']
                query = (
                    "MERGE (a:Entity {name: $h}) "
                    "MERGE (b:Entity {name: $t}) "
                    "MERGE (a)-[:" + r.replace(" ", "_") + "]->(b)"
                )
                tx.run(query, h=h, t=t)

        with self.driver.session() as session:
            session.execute_write(create, triples)

    async def txt_add_vector_entity(self, triples, kgdb_name='neo4j'):
        """æ·»åŠ å®ä½“ä¸‰å…ƒç»„"""
        self.use_database(kgdb_name)
        def _index_exists(tx, index_name):
            """æ£€æŸ¥ç´¢å¼•æ˜¯å¦å­˜åœ¨"""
            result = tx.run("SHOW INDEXES")
            for record in result:
                if record["name"] == index_name:
                    return True
            return False

        def _create_graph(tx, data):
            """æ·»åŠ ä¸€ä¸ªä¸‰å…ƒç»„"""
            for entry in data:
                tx.run("""
                MERGE (h:Entity {name: $h})
                MERGE (t:Entity {name: $t})
                MERGE (h)-[r:RELATION {type: $r}]->(t)
                """, h=entry['h'], t=entry['t'], r=entry['r'])

        def _create_vector_index(tx, dim):
            """åˆ›å»ºå‘é‡ç´¢å¼•"""
            # NOTE è¿™é‡Œæ˜¯å¦æ˜¯ä¼šé‡å¤æ„å»ºç´¢å¼•ï¼Ÿ
            index_name = "entityEmbeddings"
            if not _index_exists(tx, index_name):
                tx.run(f"""
                CREATE VECTOR INDEX {index_name}
                FOR (n: Entity) ON (n.embedding)
                OPTIONS {{indexConfig: {{
                `vector.dimensions`: {dim},
                `vector.similarity_function`: 'cosine'
                }} }};
                """)

        def _get_nodes_without_embedding(tx, entity_names):
            """è·å–æ²¡æœ‰embeddingçš„èŠ‚ç‚¹åˆ—è¡¨"""
            # æ„å»ºå‚æ•°å­—å…¸ï¼Œå°†åˆ—è¡¨è½¬æ¢ä¸º"param0"ã€"param1"ç­‰é”®å€¼å¯¹å½¢å¼
            params = {f"param{i}": name for i, name in enumerate(entity_names)}

            # æ„å»ºæŸ¥è¯¢å‚æ•°åˆ—è¡¨
            param_placeholders = ", ".join([f"${key}" for key in params.keys()])

            # æ‰§è¡ŒæŸ¥è¯¢
            result = tx.run(f"""
            MATCH (n:Entity)
            WHERE n.name IN [{param_placeholders}] AND n.embedding IS NULL
            RETURN n.name AS name
            """, params)

            return [record["name"] for record in result]

        def _batch_set_embeddings(tx, entity_embedding_pairs):
            """æ‰¹é‡è®¾ç½®å®ä½“çš„åµŒå…¥å‘é‡"""
            for entity_name, embedding in entity_embedding_pairs:
                tx.run("""
                MATCH (e:Entity {name: $name})
                CALL db.create.setNodeVectorProperty(e, 'embedding', $embedding)
                """, name=entity_name, embedding=embedding)

        # åˆ¤æ–­æ¨¡å‹åç§°æ˜¯å¦åŒ¹é…
        cur_embed_info = config.embed_model_names[config.embed_model]
        self.embed_model_name = self.embed_model_name or cur_embed_info.get('name')
        assert self.embed_model_name == cur_embed_info.get('name') or self.embed_model_name is None, \
            f"embed_model_name={self.embed_model_name}, {cur_embed_info.get('name')=}"

        with self.driver.session() as session:
            logger.info(f"Adding entity to {kgdb_name}")
            session.execute_write(_create_graph, triples)
            logger.info(f"Creating vector index for {kgdb_name} with {config.embed_model}")
            session.execute_write(_create_vector_index, cur_embed_info['dimension'])

            # æ”¶é›†æ‰€æœ‰éœ€è¦å¤„ç†çš„å®ä½“åç§°ï¼Œå»é‡
            all_entities = []
            for entry in triples:
                if entry['h'] not in all_entities:
                    all_entities.append(entry['h'])
                if entry['t'] not in all_entities:
                    all_entities.append(entry['t'])

            # ç­›é€‰å‡ºæ²¡æœ‰embeddingçš„èŠ‚ç‚¹
            nodes_without_embedding = session.execute_read(_get_nodes_without_embedding, all_entities)
            if not nodes_without_embedding:
                logger.info("æ‰€æœ‰å®ä½“å·²æœ‰embeddingï¼Œæ— éœ€é‡æ–°è®¡ç®—")
                return

            logger.info(f"éœ€è¦ä¸º{len(nodes_without_embedding)}/{len(all_entities)}ä¸ªå®ä½“è®¡ç®—embedding")

            # æ‰¹é‡å¤„ç†å®ä½“
            max_batch_size = 1024  # é™åˆ¶æ­¤éƒ¨åˆ†çš„ä¸»è¦æ˜¯å†…å­˜å¤§å° 1024 * 1024 * 4 / 1024 / 1024 = 4GB
            total_entities = len(nodes_without_embedding)

            for i in range(0, total_entities, max_batch_size):
                batch_entities = nodes_without_embedding[i:i+max_batch_size]
                logger.debug(
                    f"Processing entities batch "
                    f"{i//max_batch_size + 1}/{(total_entities-1)//max_batch_size + 1} "
                    f"({len(batch_entities)} entities)"
                )

                # æ‰¹é‡è·å–åµŒå…¥å‘é‡
                batch_embeddings = await self.aget_embedding(batch_entities)

                # å°†å®ä½“åç§°å’ŒåµŒå…¥å‘é‡é…å¯¹
                entity_embedding_pairs = list(zip(batch_entities, batch_embeddings))

                # æ‰¹é‡å†™å…¥æ•°æ®åº“
                session.execute_write(_batch_set_embeddings, entity_embedding_pairs)

            # æ•°æ®æ·»åŠ å®Œæˆåä¿å­˜å›¾ä¿¡æ¯
            self.save_graph_info()

    async def jsonl_file_add_entity(self, file_path, kgdb_name='neo4j'):
        self.status = "processing"
        kgdb_name = kgdb_name or 'neo4j'
        self.use_database(kgdb_name)  # åˆ‡æ¢åˆ°æŒ‡å®šæ•°æ®åº“
        logger.info(f"Start adding entity to {kgdb_name} with {file_path}")

        def read_triples(file_path):
            with open(file_path, 'rb') as f:
                raw_data = f.read(4096)
                result = chardet.detect(raw_data)
                encoding = result['encoding'] or 'utf-8'
                print(f"æ£€æµ‹åˆ°æ–‡ä»¶ç¼–ç : {encoding}")
            triples = []
            with open(file_path, encoding='gbk', errors='ignore') as csvfile:
                reader = csv.DictReader(csvfile)
                # æœŸæœ›åˆ—å: h, r, t
                if not set(['h', 'r', 't']).issubset(reader.fieldnames):
                    raise ValueError("CSV æ–‡ä»¶å¿…é¡»åŒ…å«åˆ—: h, r, t")
                for row in reader:
                    triples.append({
                        'h': row['h'].strip(),
                        'r': row['r'].strip(),
                        't': row['t'].strip()
                    })
            return triples

        triples = list(read_triples(file_path))

        await self.txt_add_vector_entity(triples, kgdb_name)

        self.status = "open"
        # æ›´æ–°å¹¶ä¿å­˜å›¾æ•°æ®åº“ä¿¡æ¯
        self.save_graph_info()
        return kgdb_name

    def file_Handle(
            self,
            input_file: Path,
            external_api_url: str = "http://host.docker.internal:8000/api/v1/tasks/submit"  # æ›¿æ¢ä¸ºå®é™…åœ°å€
    ):
        print(f"\n===== å¼€å§‹å‘å¤–éƒ¨æ¥å£ {external_api_url} æäº¤æ–‡ä»¶ =====")

        try:
            with open(input_file, "rb") as f:
                files = {"file": (input_file.name, f)}

                file_suffix = input_file.suffix.lower()
                data = {
                    # æ ¸å¿ƒä¿®å¤ï¼šlangä»autoæ”¹ä¸ºchï¼ˆä¸­æ–‡ï¼Œæ¥å£è¡¨æ ¼è¯†åˆ«æ”¯æŒï¼‰
                    "lang": "ch",
                    "method": "auto",
                    "formula_enable": "true",
                    "table_enable": "true",
                    "priority": "0",

                    # DeepSeek OCR ä¸“ç”¨å‚æ•°
                    "deepseek_resolution": "base",
                    "deepseek_prompt_type": "document",

                    # è§†é¢‘å¤„ç†å‚æ•°
                    "keep_audio": "false",
                    "enable_keyframe_ocr": "false",
                    "ocr_backend": "paddleocr-vl",
                    "keep_keyframes": "false",

                    # æ°´å°å»é™¤å‚æ•°
                    "remove_watermark": "false",
                    "watermark_conf_threshold": "0.35",
                    "watermark_dilation": "10"
                }

                # åç«¯é€‰æ‹©ï¼ˆä¸¥æ ¼é¿å¼€deepseek-ocrï¼‰
                if file_suffix in ['.mp3', '.wav', '.ogg', '.flac']:
                    data["backend"] = "sensevoice"
                    data["lang"] = "ch"
                elif file_suffix in ['.mp4', '.avi', '.mov', '.mkv']:
                    data["backend"] = "video"
                    data["lang"] = "ch"
                else:
                    data["backend"] = "pipeline"

                # å‘é€è¯·æ±‚
                response = requests.post(
                    url=external_api_url,
                    files=files,
                    data=data,
                    timeout=180
                )
                response.raise_for_status()
                result = response.json()

                print(f"âœ… æˆåŠŸæäº¤æ–‡ä»¶: {input_file.name}")
                print(f"   ä»»åŠ¡ID: {result.get('task_id')}")
                print(f"   åç«¯: {data['backend']} | è¯­è¨€: {data['lang']}\n")

                return result  # âœ… è¿”å›æ¥å£ç»“æœç»™è°ƒç”¨è€…ï¼ˆæ¯”å¦‚ FastAPI æ¥å£ï¼‰

        except Exception as e:
            print(f"âŒ æäº¤æ–‡ä»¶ {input_file.name} å¤±è´¥: {str(e)}\n")
            return {"success": False, "message": str(e)}

        finally:
            print("===== æ–‡ä»¶æäº¤å®Œæˆ =====")

    def copy_output(self, task_name: str) -> Path:
        # 1. å»æ‰ task_name ä¸­çš„æ–‡ä»¶åç¼€ï¼Œå¾—åˆ°æ–°å˜é‡ task_basename
        task_path = Path(task_name)
        task_basename = task_path.stem  # ä¾‹å¦‚ï¼š"é¡ºä¸°ç”µå­å‘ç¥¨_f9df.pdf" â†’ "é¡ºä¸°ç”µå­å‘ç¥¨_f9df"

        # 2. ä½¿ç”¨ task_basename æ‹¼æ¥è·¯å¾„ï¼ˆæ ¹æ®å®é™…ç›®å½•ç»“æ„è°ƒæ•´ï¼‰
        OUTPUT_DIR = Path("/app/output")
        source_md = (
                OUTPUT_DIR /
                task_basename /  # ç”¨æ— åç¼€çš„åç§°ä½œä¸ºç›®å½•
                f"{task_basename}.pdf" /  # å‡è®¾ä¸­é—´å±‚éœ€è¦å¸¦ .pdf åç¼€
                "auto" /
                f"{task_basename}.pdf.md"  # æœ€ç»ˆ md æ–‡ä»¶å
        )

        print(f"å°è¯•æŸ¥æ‰¾çš„æ–‡ä»¶è·¯å¾„: {source_md}")
        if not source_md.exists():
            raise FileNotFoundError(f"æœªæ‰¾åˆ°è¾“å‡ºæ–‡ä»¶: {source_md}")

        copy_dir = Path("/app/saves/data/copypath")
        copy_dir.mkdir(parents=True, exist_ok=True)

        target = copy_dir / source_md.name
        shutil.copy2(source_md, target)
        print(f"ğŸ“ å·²å¤åˆ¶ {source_md} â†’ {target}")
        return target

    def delete_entity(self, entity_name=None, kgdb_name="neo4j"):
        """åˆ é™¤æ•°æ®åº“ä¸­çš„æŒ‡å®šå®ä½“ä¸‰å…ƒç»„, å‚æ•°entity_nameä¸ºç©ºåˆ™åˆ é™¤å…¨éƒ¨å®ä½“"""
        self.use_database(kgdb_name)
        with self.driver.session() as session:
            if entity_name:
                session.execute_write(self._delete_specific_entity, entity_name)
            else:
                session.execute_write(self._delete_all_entities)

    def _delete_specific_entity(self, tx, entity_name):
        query = """
        MATCH (n {name: $entity_name})
        DETACH DELETE n
        """
        tx.run(query, entity_name=entity_name)

    def _delete_all_entities(self, tx):
        query = """
        MATCH (n)
        DETACH DELETE n
        """
        tx.run(query)

    def query_node(self, entity_name, threshold=0.78, kgdb_name='neo4j', hops=2, max_entities=5, **kwargs):
        """çŸ¥è¯†å›¾è°±æŸ¥è¯¢èŠ‚ç‚¹çš„å…¥å£:"""
        # TODO æ·»åŠ åˆ¤æ–­èŠ‚ç‚¹æ•°é‡ä¸º 0 åœæ­¢æ£€ç´¢
        # åˆ¤æ–­æ˜¯å¦å¯åŠ¨
        if not self.is_running():
            raise Exception("å›¾æ•°æ®åº“æœªå¯åŠ¨")

        self.use_database(kgdb_name)
        def _index_exists(tx, index_name):
            """æ£€æŸ¥ç´¢å¼•æ˜¯å¦å­˜åœ¨"""
            result = tx.run("SHOW INDEXES")
            for record in result:
                if record["name"] == index_name:
                    return True
            return False

        def query(tx, text):
            # é¦–å…ˆæ£€æŸ¥ç´¢å¼•æ˜¯å¦å­˜åœ¨
            if not _index_exists(tx, "entityEmbeddings"):
                raise Exception("å‘é‡ç´¢å¼•ä¸å­˜åœ¨ï¼Œè¯·å…ˆåˆ›å»ºç´¢å¼•")

            embedding = self.get_embedding(text)
            result = tx.run("""
            CALL db.index.vector.queryNodes('entityEmbeddings', 10, $embedding)
            YIELD node AS similarEntity, score
            RETURN similarEntity.name AS name, score
            """, embedding=embedding)
            return result.values()

        try:
            with self.driver.session() as session:
                # queryæ˜¯å‡½æ•°ï¼Œåé¢ç´§è·Ÿå‚æ•°ï¼Œè¿™é‡ŒæŸ¥è¯¢çš„æ˜¯å‘é‡ä¸æ˜¯å®ä½“åç§°
                results = session.execute_read(query, entity_name)
        except Exception as e:
            if "å‘é‡ç´¢å¼•ä¸å­˜åœ¨" in str(e):
                logger.error(f"å‘é‡ç´¢å¼•ä¸å­˜åœ¨ï¼Œè¯·å…ˆåˆ›å»ºç´¢å¼•: {e}, {traceback.format_exc()}")
                return []
            raise e

        # ç­›é€‰å‡ºåˆ†æ•°é«˜äºé˜ˆå€¼çš„å®ä½“
        qualified_entities = [result[0] for result in results[:max_entities] if result[1] > threshold]
        logger.debug(f"Graph Query Entities: {entity_name}, {qualified_entities=}")

        # å¯¹æ¯ä¸ªåˆæ ¼çš„å®ä½“è¿›è¡ŒæŸ¥è¯¢
        all_query_results = []
        for entity in qualified_entities:
            query_result = self.query_specific_entity(entity_name=entity, hops=hops, kgdb_name=kgdb_name)
            all_query_results.extend(query_result)

        return all_query_results

    def query_specific_entity(self, entity_name, kgdb_name='neo4j', hops=2, limit=100):
        """æŸ¥è¯¢æŒ‡å®šå®ä½“ä¸‰å…ƒç»„ä¿¡æ¯ï¼ˆæ— å‘å…³ç³»ï¼‰"""
        if not entity_name:
            logger.warning("å®ä½“åç§°ä¸ºç©º")
            return []

        self.use_database(kgdb_name)

        def query(tx, entity_name, hops, limit):
            try:
                # hopsæŸ¥è¯¢æ·±åº¦
                query_str = f"""
                MATCH (n {{name: $entity_name}})-[r*1..{hops}]-(m)
                RETURN n AS n, r, m AS m
                LIMIT $limit
                """
                result = tx.run(query_str, entity_name=entity_name, limit=limit)

                if not result:
                    logger.info(f"æœªæ‰¾åˆ°å®ä½“ {entity_name} çš„ç›¸å…³ä¿¡æ¯")
                    return []

                values = result.values()
                # å®‰å…¨åœ°æ¸…ç†embeddingå±æ€§
                values = clean_triples_embedding(values)
                return values

            except Exception as e:
                logger.error(f"æŸ¥è¯¢å®ä½“ {entity_name} å¤±è´¥: {str(e)}")
                return []

        try:
            with self.driver.session() as session:
                return session.execute_read(query, entity_name, hops, limit)
        except Exception as e:
            logger.error(f"æ•°æ®åº“ä¼šè¯å¼‚å¸¸: {str(e)}")
            return []

    def query_all_nodes_and_relationships(self, kgdb_name='neo4j', hops = 2):
        """æŸ¥è¯¢å›¾æ•°æ®åº“ä¸­æ‰€æœ‰ä¸‰å…ƒç»„ä¿¡æ¯ NEVER USE"""
        self.use_database(kgdb_name)
        def query(tx, hops):
            result = tx.run(f"""
            MATCH (n)-[r*1..{hops}]->(m)
            RETURN n AS n, r, m AS m
            """)
            values = result.values()
            values = clean_triples_embedding(values)
            return values

        with self.driver.session() as session:
            return session.execute_read(query, hops)

    def query_by_relationship_type(self, relationship_type, kgdb_name='neo4j', hops = 2):
        """æŸ¥è¯¢æŒ‡å®šå…³ç³»ä¸‰å…ƒç»„ä¿¡æ¯ NEVER USE"""
        self.use_database(kgdb_name)
        def query(tx, relationship_type, hops):
            result = tx.run(f"""
            MATCH (n)-[r:`{relationship_type}`*1..{hops}]->(m)
            RETURN n AS n, r, m AS m
            """)
            values = result.values()
            values = clean_triples_embedding(values)
            return values

        with self.driver.session() as session:
            return session.execute_read(query, relationship_type, hops)

    def query_entity_like(self, keyword, kgdb_name='neo4j', hops = 2):
        """æ¨¡ç³ŠæŸ¥è¯¢ NEVER USE"""
        self.use_database(kgdb_name)
        def query(tx, keyword, hops):
            result = tx.run(f"""
            MATCH (n:Entity)
            WHERE n.name CONTAINS $keyword
            MATCH (n)-[r*1..{hops}]->(m)
            RETURN n AS n, r, m AS m
            """, keyword=keyword)
            values = result.values()
            values = clean_triples_embedding(values)
            return values

        with self.driver.session() as session:
            return session.execute_read(query, keyword, hops)

    def query_node_info(self, node_name, kgdb_name='neo4j', hops = 2):
        """æŸ¥è¯¢æŒ‡å®šèŠ‚ç‚¹çš„è¯¦ç»†ä¿¡æ¯è¿”å›ä¿¡æ¯ NEVER USE"""
        self.use_database(kgdb_name)  # åˆ‡æ¢åˆ°æŒ‡å®šæ•°æ®åº“
        def query(tx, node_name, hops):
            result = tx.run(f"""
            MATCH (n {{name: $node_name}})
            OPTIONAL MATCH (n)-[r*1..{hops}]->(m)
            RETURN n AS n, r, m AS m
            """, node_name=node_name)
            values = result.values()
            values = clean_triples_embedding(values)
            return values

        with self.driver.session() as session:
            return session.execute_read(query, node_name, hops)

    async def aget_embedding(self, text):
        from src import knowledge_base

        if isinstance(text, list):
            outputs = await knowledge_base.embed_model.abatch_encode(text, batch_size=40)
            return outputs
        else:
            outputs = await knowledge_base.embed_model.aencode(text)
            return outputs

    def get_embedding(self, text):
        from src import knowledge_base

        if isinstance(text, list):
            outputs = knowledge_base.embed_model.batch_encode(text, batch_size=40)
            return outputs
        else:
            outputs = knowledge_base.embed_model.encode([text])[0]
            return outputs

    def set_embedding(self, tx, entity_name, embedding):
        tx.run("""
        MATCH (e:Entity {name: $name})
        CALL db.create.setNodeVectorProperty(e, 'embedding', $embedding)
        """, name=entity_name, embedding=embedding)

    def get_graph_info(self, graph_name="neo4j"):
        self.use_database(graph_name)
        def query(tx):
            entity_count = tx.run("MATCH (n) RETURN count(n) AS count").single()["count"]
            relationship_count = tx.run("MATCH ()-[r]->() RETURN count(r) AS count").single()["count"]
            triples_count = tx.run("MATCH (n)-[r]->(m) RETURN count(n) AS count").single()["count"]

            # è·å–æ‰€æœ‰æ ‡ç­¾
            labels = tx.run("CALL db.labels() YIELD label RETURN collect(label) AS labels").single()["labels"]

            return {
                "graph_name": graph_name,
                "entity_count": entity_count,
                "relationship_count": relationship_count,
                "triples_count": triples_count,
                "labels": labels,
                "status": self.status,
                "embed_model_name": self.embed_model_name,
                "unindexed_node_count": self.query_nodes_without_embedding(graph_name)
            }

        try:
            if self.status == "open" and self.driver and self.is_running():
                # è·å–æ•°æ®åº“ä¿¡æ¯
                with self.driver.session() as session:
                    graph_info = session.execute_read(query)

                    # æ·»åŠ æ—¶é—´æˆ³
                    from datetime import datetime
                    graph_info["last_updated"] = datetime.now().isoformat()
                    return graph_info

        except Exception as e:
            logger.error(f"è·å–å›¾æ•°æ®åº“ä¿¡æ¯å¤±è´¥ï¼š{e}, {traceback.format_exc()}")
            return None

    def save_graph_info(self, graph_name="neo4j"):
        """
        å°†å›¾æ•°æ®åº“çš„åŸºæœ¬ä¿¡æ¯ä¿å­˜åˆ°å·¥ä½œç›®å½•ä¸­çš„JSONæ–‡ä»¶
        ä¿å­˜çš„ä¿¡æ¯åŒ…æ‹¬ï¼šæ•°æ®åº“åç§°ã€çŠ¶æ€ã€åµŒå…¥æ¨¡å‹åç§°ç­‰
        """
        try:
            graph_info = self.get_graph_info(graph_name)
            if graph_info is None:
                logger.error("å›¾æ•°æ®åº“ä¿¡æ¯ä¸ºç©ºï¼Œæ— æ³•ä¿å­˜")
                return False

            info_file_path = os.path.join(self.work_dir, "graph_info.json")
            with open(info_file_path, 'w', encoding='utf-8') as f:
                json.dump(graph_info, f, ensure_ascii=False, indent=2)

            # logger.info(f"å›¾æ•°æ®åº“ä¿¡æ¯å·²ä¿å­˜åˆ°ï¼š{info_file_path}")
            return True
        except Exception as e:
            logger.error(f"ä¿å­˜å›¾æ•°æ®åº“ä¿¡æ¯å¤±è´¥ï¼š{e}")
            return False

    def query_nodes_without_embedding(self, kgdb_name='neo4j'):
        """æŸ¥è¯¢æ²¡æœ‰åµŒå…¥å‘é‡çš„èŠ‚ç‚¹

        Returns:
            list: æ²¡æœ‰åµŒå…¥å‘é‡çš„èŠ‚ç‚¹åˆ—è¡¨
        """
        self.use_database(kgdb_name)

        def query(tx):
            result = tx.run("""
            MATCH (n:Entity)
            WHERE n.embedding IS NULL
            RETURN n.name AS name
            """)
            return [record["name"] for record in result]

        with self.driver.session() as session:
            return session.execute_read(query)

    def load_graph_info(self):
        """
        ä»å·¥ä½œç›®å½•ä¸­çš„JSONæ–‡ä»¶åŠ è½½å›¾æ•°æ®åº“çš„åŸºæœ¬ä¿¡æ¯
        è¿”å›Trueè¡¨ç¤ºåŠ è½½æˆåŠŸï¼ŒFalseè¡¨ç¤ºåŠ è½½å¤±è´¥
        """
        try:
            info_file_path = os.path.join(self.work_dir, "graph_info.json")
            if not os.path.exists(info_file_path):
                logger.debug(f"å›¾æ•°æ®åº“ä¿¡æ¯æ–‡ä»¶ä¸å­˜åœ¨ï¼š{info_file_path}")
                return False

            with open(info_file_path, encoding='utf-8') as f:
                graph_info = json.load(f)

            # æ›´æ–°å¯¹è±¡å±æ€§
            if graph_info.get("embed_model_name"):
                self.embed_model_name = graph_info["embed_model_name"]

            # å¦‚æœéœ€è¦ï¼Œå¯ä»¥åŠ è½½æ›´å¤šä¿¡æ¯
            # æ³¨æ„ï¼šè¿™é‡Œä¸æ›´æ–°self.kgdb_nameï¼Œå› ä¸ºå®ƒæ˜¯åœ¨åˆå§‹åŒ–æ—¶è®¾ç½®çš„

            logger.info(f"å·²åŠ è½½å›¾æ•°æ®åº“ä¿¡æ¯ï¼Œæœ€åæ›´æ–°æ—¶é—´ï¼š{graph_info.get('last_updated')}")
            return True
        except Exception as e:
            logger.error(f"åŠ è½½å›¾æ•°æ®åº“ä¿¡æ¯å¤±è´¥ï¼š{e}")
            return False

    def add_embedding_to_nodes(self, node_names=None, kgdb_name='neo4j'):
        """ä¸ºèŠ‚ç‚¹æ·»åŠ åµŒå…¥å‘é‡

        Args:
            node_names (list, optional): è¦æ·»åŠ åµŒå…¥å‘é‡çš„èŠ‚ç‚¹åç§°åˆ—è¡¨ï¼ŒNoneè¡¨ç¤ºæ‰€æœ‰æ²¡æœ‰åµŒå…¥å‘é‡çš„èŠ‚ç‚¹
            kgdb_name (str, optional): å›¾æ•°æ®åº“åç§°ï¼Œé»˜è®¤ä¸º'neo4j'

        Returns:
            int: æˆåŠŸæ·»åŠ åµŒå…¥å‘é‡çš„èŠ‚ç‚¹æ•°é‡
        """
        self.use_database(kgdb_name)

        # å¦‚æœnode_namesä¸ºNoneï¼Œåˆ™è·å–æ‰€æœ‰æ²¡æœ‰åµŒå…¥å‘é‡çš„èŠ‚ç‚¹
        if node_names is None:
            node_names = self.query_nodes_without_embedding(kgdb_name)

        count = 0
        with self.driver.session() as session:
            for node_name in node_names:
                try:
                    embedding = self.get_embedding(node_name)
                    session.execute_write(self.set_embedding, node_name, embedding)
                    count += 1
                except Exception as e:
                    logger.error(f"ä¸ºèŠ‚ç‚¹ '{node_name}' æ·»åŠ åµŒå…¥å‘é‡å¤±è´¥: {e}, {traceback.format_exc()}")

        return count


    def _extract_relationship_info(self, relationship, source_name=None, target_name=None, node_dict=None):
        """
        æå–å…³ç³»ä¿¡æ¯å¹¶è¿”å›æ ¼å¼åŒ–çš„èŠ‚ç‚¹å’Œè¾¹ä¿¡æ¯
        """
        rel_id = relationship.element_id
        nodes = relationship.nodes
        if len(nodes) != 2:
            return None, None

        source, target = nodes
        source_id = source.element_id
        target_id = target.element_id

        source_name = node_dict[source_id]["name"] if source_name is None else source_name
        target_name = node_dict[target_id]["name"] if target_name is None else target_name

        relationship_type = relationship._properties.get("type", "unknown")
        if relationship_type == "unknown":
            relationship_type = relationship.type

        edge_info = {
            "id": rel_id,
            "type": relationship_type,
            "source_id": source_id,
            "target_id": target_id,
            "source_name": source_name,
            "target_name": target_name,
        }

        node_info = [
            {"id": source_id, "name": source_name},
            {"id": target_id, "name": target_name},
        ]

        return node_info, edge_info

    def format_general_results(self, results):
        formatted_results = {"nodes": [], "edges": []}

        for item in results:
            relationship = item[1]
            source_name = item[0]._properties.get("name", "unknown")
            target_name = item[2]._properties.get("name", "unknown") if len(item) > 2 else "unknown"

            node_info, edge_info = self._extract_relationship_info(relationship, source_name, target_name)
            if node_info is None or edge_info is None:
                continue

            for node in node_info:
                if node["id"] not in [n["id"] for n in formatted_results["nodes"]]:
                    formatted_results["nodes"].append(node)

            formatted_results["edges"].append(edge_info)

        return formatted_results

    def format_query_result_to_graph(self, query_results):
        """å°†æ£€ç´¢åˆ°çš„ç»“æœè½¬æ¢ä¸º {"nodes": [], "edges": []} çš„æ ¼å¼

        ä¾‹å¦‚ï¼š
        {
            "nodes": [
                {
                    "id": "4:5efbff88-72ef-44f9-b867-6c0e164a4a13:103",
                    "name": "å¼ è‹¥é”¦"
                },
                {
                    "id": "4:5efbff88-72ef-44f9-b867-6c0e164a4a13:20",
                    "name": "è´¾å®ç‰"
                },
                ....
            ],
            "edges": [
                {
                    "id": "5:5efbff88-72ef-44f9-b867-6c0e164a4a13:71",
                    "type": "å¥´ä»†",
                    "source_id": "4:5efbff88-72ef-44f9-b867-6c0e164a4a13:88",
                    "target_id": "4:5efbff88-72ef-44f9-b867-6c0e164a4a13:20",
                    "source_name": "å®‹å¬·å¬·",
                    "target_name": "è´¾å®ç‰"
                },
                ....
            ]
        }
        """
        formatted_results = {"nodes": [], "edges": []}
        node_dict = {}
        edge_dict = {}

        for item in query_results:
            # æ£€æŸ¥æ•°æ®æ ¼å¼
            if len(item) < 2 or not isinstance(item[1], list):
                continue

            node_dict[item[0].element_id] = dict(id=item[0].element_id, name=item[0]._properties.get("name", "Unknown"))
            node_dict[item[2].element_id] = dict(id=item[2].element_id, name=item[2]._properties.get("name", "Unknown"))

            # å¤„ç†å…³ç³»åˆ—è¡¨ä¸­çš„æ¯ä¸ªå…³ç³»
            for i, relationship in enumerate(item[1]):
                try:
                    # æå–å…³ç³»ä¿¡æ¯
                    node_info, edge_info = self._extract_relationship_info(relationship, node_dict=node_dict)
                    if node_info is None or edge_info is None:
                        continue

                    # æ·»åŠ è¾¹
                    edge_dict[edge_info["id"]] = edge_info
                except Exception as e:
                    logger.error(f"å¤„ç†å…³ç³»æ—¶å‡ºé”™: {e}, å…³ç³»: {relationship}, {traceback.format_exc()}")
                    continue

        # å°†èŠ‚ç‚¹å­—å…¸è½¬æ¢ä¸ºåˆ—è¡¨
        formatted_results["nodes"] = list(node_dict.values())
        formatted_results["edges"] = list(edge_dict.values())


        return formatted_results

def clean_triples_embedding(triples):
    for item in triples:
        if hasattr(item[0], '_properties'):
            item[0]._properties['embedding'] = None
        if hasattr(item[2], '_properties'):
            item[2]._properties['embedding'] = None
    return triples


if __name__ == "__main__":
    pass
